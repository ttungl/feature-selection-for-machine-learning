{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant features\n",
    "\n",
    "Constant features are those that show the same value, just one value, for all the observations of the dataset. This is, the same value for all the rows of the dataset. These features provide no information that allows a machine learning model to discriminate or predict a target.\n",
    "\n",
    "Identifying and removing constant features, is an easy first step towards feature selection and more easily interpretable machine learning models.\n",
    "\n",
    "Here I will demonstrate how to identify constant features using the Santander Customer Satisfaction dataset from Kaggle. \n",
    "\n",
    "To identify constant features, we can use the VarianceThreshold function from sklearn, or we can code it ourselves. I will show 2 snippets of code with both procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 371)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the Santander customer satisfaction dataset from Kaggle\n",
    "# I load just a few rows for the demonstration\n",
    "\n",
    "data = pd.read_csv('santander.csv', nrows=50000)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the presence of null data.\n",
    "# The snippets below will be able to compare nan values between 2 columns,\n",
    "# so in principle missing data are not a problem.\n",
    "# in any case, we see that there are no missing data in this dataset\n",
    "\n",
    "[col for col in data.columns if data[col].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 370), (15000, 370))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using variance threshold from sklearn\n",
    "\n",
    "Variance threshold from sklearn is a simple baseline approach to feature selection. It removes all features which variance doesnâ€™t meet some threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0)\n",
    "sel.fit(X_train)  # fit finds the features with zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_support is a boolean vector that indicates which features are retained\n",
    "# if we sum over get_support, we get the number of features that are not constant\n",
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way of finding non-constant features is like this:\n",
    "len(X_train.columns[sel.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ind_var2_0',\n",
       " 'ind_var2',\n",
       " 'ind_var13_medio_0',\n",
       " 'ind_var13_medio',\n",
       " 'ind_var27_0',\n",
       " 'ind_var28_0',\n",
       " 'ind_var28',\n",
       " 'ind_var27',\n",
       " 'ind_var34_0',\n",
       " 'ind_var34',\n",
       " 'ind_var41',\n",
       " 'ind_var46_0',\n",
       " 'ind_var46',\n",
       " 'num_var13_medio_0',\n",
       " 'num_var13_medio',\n",
       " 'num_var27_0',\n",
       " 'num_var28_0',\n",
       " 'num_var28',\n",
       " 'num_var27',\n",
       " 'num_var34_0',\n",
       " 'num_var34',\n",
       " 'num_var41',\n",
       " 'num_var46_0',\n",
       " 'num_var46',\n",
       " 'saldo_var13_medio',\n",
       " 'saldo_var28',\n",
       " 'saldo_var27',\n",
       " 'saldo_var34',\n",
       " 'saldo_var41',\n",
       " 'saldo_var46',\n",
       " 'delta_imp_amort_var34_1y3',\n",
       " 'delta_imp_reemb_var33_1y3',\n",
       " 'delta_num_reemb_var33_1y3',\n",
       " 'imp_amort_var18_hace3',\n",
       " 'imp_amort_var34_hace3',\n",
       " 'imp_amort_var34_ult1',\n",
       " 'imp_reemb_var13_hace3',\n",
       " 'imp_reemb_var17_hace3',\n",
       " 'imp_reemb_var33_hace3',\n",
       " 'imp_reemb_var33_ult1',\n",
       " 'imp_trasp_var17_out_hace3',\n",
       " 'imp_trasp_var33_out_hace3',\n",
       " 'imp_venta_var44_hace3',\n",
       " 'num_var2_0_ult1',\n",
       " 'num_var2_ult1',\n",
       " 'num_meses_var13_medio_ult3',\n",
       " 'num_reemb_var13_hace3',\n",
       " 'num_reemb_var17_hace3',\n",
       " 'num_reemb_var33_hace3',\n",
       " 'num_reemb_var33_ult1',\n",
       " 'num_trasp_var17_out_hace3',\n",
       " 'num_trasp_var33_out_hace3',\n",
       " 'num_venta_var44_hace3',\n",
       " 'saldo_var2_ult1',\n",
       " 'saldo_medio_var13_medio_hace2',\n",
       " 'saldo_medio_var13_medio_hace3',\n",
       " 'saldo_medio_var13_medio_ult1',\n",
       " 'saldo_medio_var13_medio_ult3']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally we can print the constant features\n",
    "print(\n",
    "    len([\n",
    "        x for x in X_train.columns\n",
    "        if x not in X_train.columns[sel.get_support()]\n",
    "    ]))\n",
    "\n",
    "[x for x in X_train.columns if x not in X_train.columns[sel.get_support()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 58 columns / variables are constant. This means that 58 variables show the same value, just one value, for all the observations of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualise the values of one of the constant variables\n",
    "# as an example\n",
    "\n",
    "X_train['ind_var2_0'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the transform function to reduce the training and testing sets. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 312), (15000, 312))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding it ourselves\n",
    "\n",
    "In the following cells, I will show an alternative to the VarianceThreshold function of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 370), (15000, 370))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset again\n",
    "data = pd.read_csv('santander.csv', nrows=50000)\n",
    "\n",
    "# separate train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# short and easy: find constant features\n",
    "# in this case, all features are numeric, so this will suffice\n",
    "\n",
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "len(constant_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 312), (15000, 312))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can then drop these columns from the train and test sets\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see how by removing constant features, we managed to reduced the feature space quite a bit.\n",
    "\n",
    "Both varianceThreshold and the snippet of code I provided work with numerical variables. What can we do to find constant categorical variables?\n",
    "\n",
    "One alternatively is to encode the categories as numbers and then use the code above. But then you will put effort in pre-processing variables that are not informative.\n",
    "\n",
    "Alternatively, you can use the code below.\n",
    "\n",
    "### Removing constant features for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 370), (15000, 370))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset again\n",
    "data = pd.read_csv('santander.csv', nrows=50000)\n",
    "\n",
    "# separate train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['TARGET'], axis=1),\n",
    "    data['TARGET'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                               object\n",
       "var3                             object\n",
       "var15                            object\n",
       "imp_ent_var16_ult1               object\n",
       "imp_op_var39_comer_ult1          object\n",
       "imp_op_var39_comer_ult3          object\n",
       "imp_op_var40_comer_ult1          object\n",
       "imp_op_var40_comer_ult3          object\n",
       "imp_op_var40_efect_ult1          object\n",
       "imp_op_var40_efect_ult3          object\n",
       "imp_op_var40_ult1                object\n",
       "imp_op_var41_comer_ult1          object\n",
       "imp_op_var41_comer_ult3          object\n",
       "imp_op_var41_efect_ult1          object\n",
       "imp_op_var41_efect_ult3          object\n",
       "imp_op_var41_ult1                object\n",
       "imp_op_var39_efect_ult1          object\n",
       "imp_op_var39_efect_ult3          object\n",
       "imp_op_var39_ult1                object\n",
       "imp_sal_var16_ult1               object\n",
       "ind_var1_0                       object\n",
       "ind_var1                         object\n",
       "ind_var2_0                       object\n",
       "ind_var2                         object\n",
       "ind_var5_0                       object\n",
       "ind_var5                         object\n",
       "ind_var6_0                       object\n",
       "ind_var6                         object\n",
       "ind_var8_0                       object\n",
       "ind_var8                         object\n",
       "                                  ...  \n",
       "saldo_medio_var12_ult3           object\n",
       "saldo_medio_var13_corto_hace2    object\n",
       "saldo_medio_var13_corto_hace3    object\n",
       "saldo_medio_var13_corto_ult1     object\n",
       "saldo_medio_var13_corto_ult3     object\n",
       "saldo_medio_var13_largo_hace2    object\n",
       "saldo_medio_var13_largo_hace3    object\n",
       "saldo_medio_var13_largo_ult1     object\n",
       "saldo_medio_var13_largo_ult3     object\n",
       "saldo_medio_var13_medio_hace2    object\n",
       "saldo_medio_var13_medio_hace3    object\n",
       "saldo_medio_var13_medio_ult1     object\n",
       "saldo_medio_var13_medio_ult3     object\n",
       "saldo_medio_var17_hace2          object\n",
       "saldo_medio_var17_hace3          object\n",
       "saldo_medio_var17_ult1           object\n",
       "saldo_medio_var17_ult3           object\n",
       "saldo_medio_var29_hace2          object\n",
       "saldo_medio_var29_hace3          object\n",
       "saldo_medio_var29_ult1           object\n",
       "saldo_medio_var29_ult3           object\n",
       "saldo_medio_var33_hace2          object\n",
       "saldo_medio_var33_hace3          object\n",
       "saldo_medio_var33_ult1           object\n",
       "saldo_medio_var33_ult3           object\n",
       "saldo_medio_var44_hace2          object\n",
       "saldo_medio_var44_hace3          object\n",
       "saldo_medio_var44_ult1           object\n",
       "saldo_medio_var44_ult3           object\n",
       "var38                            object\n",
       "Length: 370, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will transform all these numeric features into\n",
    "# categorical features for the demonstration\n",
    "# to simulate that they are categorical\n",
    "\n",
    "X_train = X_train.astype('O')\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now find those columns that contain only 1 label:\n",
    "constant_features = [\n",
    "    feat for feat in X_train.columns if len(X_train[feat].unique()) == 1\n",
    "]\n",
    "\n",
    "len(constant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, we observe 58 variables that show only 1 value across all the observations of the dataset. We can appreciate the usefulness of looking out for constant variables at the beginning of any modeling exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "20px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
