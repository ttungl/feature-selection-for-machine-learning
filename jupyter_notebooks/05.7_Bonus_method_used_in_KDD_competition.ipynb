{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Method used in KDD 2009 competition\n",
    "\n",
    "I will describe the feature selection approach undertaken by data scientists at the University of Melbourne for the [KDD 2009](http://www.kdd.org/kdd-cup/view/kdd-cup-2009) data science competition. The task consisted in predicting churn based on a dataset with a huge number of features.\n",
    "\n",
    "The authors describe this procedure as an aggressive non-parametric feature selection procedure, that is based in contemplating the relationship between the feature and the target. Therefore, this method should be classified as a filter method.\n",
    "\n",
    "**The procedure consists in the following steps**:\n",
    "\n",
    "For each categorical variable:\n",
    "\n",
    "    1) Separate into train and test\n",
    "\n",
    "    2) Determine the mean value of the target within each label of the categorical variable using the train set\n",
    "\n",
    "    3) Use that mean target value per label as the prediction in the test set and calculate the roc-auc.\n",
    "\n",
    "For each numerical variable:\n",
    "\n",
    "    1) Separate into train and test\n",
    "    \n",
    "    2) Divide the variable into 100 quantiles\n",
    "\n",
    "    3) Calculate the mean target within each quantile using the training set \n",
    "\n",
    "    4) Use that mean target value / bin as the prediction on the test set and calculate the roc-auc\n",
    "\n",
    "\n",
    "The authors quote the following advantages of the method:\n",
    "\n",
    "- Speed: computing mean and quantiles is direct and efficient\n",
    "- Stability respect to scale: extreme values for continuous variables do not skew the predictions\n",
    "- Comparable between categorical and numerical variables\n",
    "- Accommodation of non-linearities\n",
    "\n",
    "See my notes at the end of the notebook for a discussion on the method and the authors assumptions.\n",
    "\n",
    "You will understand better the procedure as I proceed with the demonstration. I will use the titanic dataset from Kaggle.\n",
    "\n",
    "**Reference**:\n",
    "[Predicting customer behaviour: The University of Melbourne's KDD Cup Report. Miller et al. JMLR Workshop and Conference Proceedings 7:45-55](http://www.mtome.com/Publications/CiML/CiML-v3-book.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the titanic dataset\n",
    "data = pd.read_csv('titanic.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'C', 'E', 'G', 'D', 'A', 'B', 'F', 'T'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable preprocessing:\n",
    "# Cabin contains missing data\n",
    "# I will replace missing data by adding a category \"Missing\"\n",
    "# then I will narrow down the different cabins by selecting only the\n",
    "# first letter, which represents the deck in which the cabin was located\n",
    "\n",
    "data['Cabin'].fillna('Missing', inplace=True)\n",
    "\n",
    "# captures first letter of string (the letter of the cabin)\n",
    "data['Cabin'] = data['Cabin'].str[0]\n",
    "data['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((623, 5), (268, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "# I will only use the categorical variables and the target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['Pclass', 'Sex', 'Embarked', 'Cabin', 'Survived']],\n",
    "    data['Survived'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection on categorical variables\n",
    "\n",
    "First, I will demonstrate the feature selection procedure over categorical variables. The Titanic dataset contains 4 categorical variables, which are Sex, Pclass, Cabin and Embarked.\n",
    "\n",
    "In the next cell I create a function that calculates the mean of Survival (and this is equivalent to the probability of survival) of the passenger, within each label of a categorical variable. It creates a dictionary, using the training set only, that maps each label of the training set variable, to a probability of survival.\n",
    "\n",
    "Then, the function replaces the label both in train and test set, by the probability of survival. It is like making a prediction on the outcome, by using only the label of the variable.\n",
    "\n",
    "In this way, the function replaces the original strings, by probabilities. \n",
    "\n",
    "The bottom line of this method is that we **use just the label of the variable to estimate the probability of survival of the passenger**. \n",
    "A bit like \"Tell me which one was your Cabin, and I will tell you your probability of Survival\".\n",
    "\n",
    "If the labels of a categorical variable and therefore the categorical variable are good predictors, then, we should obtain a roc-auc above 0.5 for that variable, when we evaluate those probabilities with the real outcome, which is whether the passenger survived or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>1</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.341357</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>0.753488</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>3</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.341357</td>\n",
       "      <td>0.303609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.341357</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>3</td>\n",
       "      <td>0.753488</td>\n",
       "      <td>0.564815</td>\n",
       "      <td>0.303609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass       Sex  Embarked     Cabin\n",
       "857       1  0.196078  0.341357  0.740741\n",
       "52        1  0.753488  0.564815  0.692308\n",
       "386       3  0.196078  0.341357  0.303609\n",
       "124       1  0.196078  0.341357  0.692308\n",
       "578       3  0.753488  0.564815  0.303609"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_encoding(df_train, df_test):\n",
    "    # temporary copy of the original dataframes\n",
    "    df_train_temp = df_train.copy()\n",
    "    df_test_temp = df_test.copy()\n",
    "    \n",
    "    for col in ['Sex', 'Cabin', 'Embarked', 'Cabin']:\n",
    "        # make a dictionary mapping labels / categories to the mean target for that label\n",
    "        risk_dict = df_train.groupby([col])['Survived'].mean().to_dict()\n",
    "        \n",
    "        # re-map the labels\n",
    "        df_train_temp[col] = df_train[col].map(risk_dict)\n",
    "        df_test_temp[col] = df_test[col].map(risk_dict)\n",
    "    \n",
    "    # drop the target\n",
    "    df_train_temp.drop(['Survived'], axis=1, inplace=True)\n",
    "    df_test_temp.drop(['Survived'], axis=1, inplace=True)        \n",
    "    return df_train_temp, df_test_temp\n",
    "        \n",
    "X_train_enc, X_test_enc = mean_encoding(X_train, X_test)\n",
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strings were replaced by probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now, I calculate a roc-auc value, using the probabilities that we used to\n",
    "# replace the labels, and comparing it with the true target:\n",
    "\n",
    "roc_values = []\n",
    "for feature in ['Sex', 'Cabin', 'Embarked', 'Cabin']:\n",
    "    roc_values.append(roc_auc_score(y_test, X_test_enc[feature])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex         0.771667\n",
       "Cabin       0.641637\n",
       "Cabin       0.641637\n",
       "Embarked    0.577500\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I make a series for easy visualisation\n",
    "m1 = pd.Series(roc_values)\n",
    "m1.index = ['Sex', 'Cabin', 'Embarked', 'Cabin']\n",
    "m1.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that all the features are important, because the roc_auc for all of them is higher than 0.5. In addition, Sex seems to be the most important feature to predict survival, as its roc_auc is the highest.\n",
    "\n",
    "As you see, this is a very powerful, yet straightforward approach to feature selection.\n",
    "\n",
    "### Feature Selection on numerical variables\n",
    "\n",
    "The procedure is exactly the same, but it requires one additional first step which is to divide the continuous variable into bins. The authors of the method divide the variable in 100 quantiles, that is 100 bins. In principle, you could divide the variable in less bins. Here I will divide the variable in 10 bins only.\n",
    "\n",
    "I will work with the numerical variables Age and Fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('titanic.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((623, 3), (268, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['Age', 'Fare', 'Survived']],\n",
    "    data['Survived'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_binned</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>Q10</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Q9</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Q1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Q10</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Q1</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Q4</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q3</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Q6</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Q4</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age_binned   Age\n",
       "857        Q10  51.0\n",
       "52          Q9  49.0\n",
       "386         Q1   1.0\n",
       "124        Q10  54.0\n",
       "578        NaN   NaN\n",
       "549         Q1   8.0\n",
       "118         Q4  24.0\n",
       "12          Q3  20.0\n",
       "157         Q6  30.0\n",
       "127         Q4  24.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will divide Age in 10 bins. I use the qcut (quantile cut)\n",
    "# function from pandas and I indicate that I want 9 cutting points,\n",
    "# thus 10 bins.\n",
    "# retbins= True indicates that I want to capture the limits of\n",
    "# each interval (so I can then use them to cut the test set)\n",
    "\n",
    "# create 10 labels, one for each quantile\n",
    "# instead of having the quantile limits, the new variable\n",
    "# will have labels in its bins\n",
    "\n",
    "labels = ['Q' + str(i + 1) for i in range(0, 10)]\n",
    "\n",
    "X_train['Age_binned'], intervals = pd.qcut(\n",
    "    X_train.Age,\n",
    "    10,\n",
    "    labels=labels,\n",
    "    retbins=True,\n",
    "    precision=3,\n",
    "    duplicates='drop',\n",
    ")\n",
    "\n",
    "X_train[['Age_binned', 'Age']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can count the number of bins. It has 11 because Age contains missing data. \n",
    "# Those are kept in a separate bin (NaN)\n",
    "len(X_train.Age_binned.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Q10, Q9, Q1, NaN, Q4, ..., Q6, Q2, Q7, Q5, Q8]\n",
       "Length: 11\n",
       "Categories (10, object): [Q1 < Q10 < Q2 < Q3 ... Q6 < Q7 < Q8 < Q9]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we see the NaN values\n",
    "X_train.Age_binned.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.67,  13.1 ,  19.  ,  22.  ,  25.4 ,  29.  ,  32.  ,  36.  ,\n",
       "         41.  ,  49.  ,  80.  ]), 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and these are the cutting points of the intervals\n",
    "intervals, len(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_binned</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Q1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Q5</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Q8</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Q6</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Q4</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age_binned   Age\n",
       "495        NaN   NaN\n",
       "648        NaN   NaN\n",
       "278         Q1   7.0\n",
       "31         NaN   NaN\n",
       "255         Q5  29.0\n",
       "298        NaN   NaN\n",
       "609         Q8  40.0\n",
       "318         Q6  31.0\n",
       "484         Q4  25.0\n",
       "367        NaN   NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I use the boundaries calculated in the previous cell to\n",
    "# bin the testing set\n",
    "\n",
    "X_test['Age_binned'] = pd.cut(x = X_test.Age, bins=intervals, labels=labels)\n",
    "X_test[['Age_binned', 'Age']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as before, it shows 10 bins and the NaN separately.\n",
    "len(X_test.Age_binned.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NaN, Q1, Q5, Q8, Q6, ..., Q2, Q7, Q3, Q10, Q9]\n",
       "Length: 11\n",
       "Categories (10, object): [Q1 < Q10 < Q2 < Q3 ... Q6 < Q7 < Q8 < Q9]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we see the NaN values\n",
    "X_test.Age_binned.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Age_binned    121\n",
       " dtype: int64, Age_binned    57\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and here we count the NaN values\n",
    "X_train[['Age_binned']].isnull().sum(), X_test[['Age_binned']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in order to replace the NaN values by a new category\n",
    "# called \"Missing\", first I need to recast the variables as\n",
    "# objects\n",
    "\n",
    "X_train['Age_binned'] = X_train['Age_binned'].astype('O')\n",
    "X_test['Age_binned'] = X_test['Age_binned'].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and now I replace the missing values with a new category\n",
    "X_train['Age_binned'].fillna('Missing', inplace=True)\n",
    "X_test['Age_binned'].fillna('Missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857    0.360000\n",
       "52     0.360000\n",
       "386    0.568627\n",
       "124    0.360000\n",
       "578    0.305785\n",
       "Name: Age_binned, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I create a dictionary that maps the bins to the mean of survival\n",
    "risk_dict = X_train.groupby(['Age_binned'])['Survived'].mean().to_dict()\n",
    "\n",
    "# re-map the labels, I replace the bins by the probability of survival\n",
    "X_train['Age_binned'] = X_train['Age_binned'].map(risk_dict)\n",
    "X_test['Age_binned'] = X_test['Age_binned'].map(risk_dict)\n",
    "\n",
    "X_train['Age_binned'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57238095238095243"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, I calculate a roc-auc value, using the probabilities that we used to\n",
    "# replace the labels, and comparing it with the true target:\n",
    "\n",
    "roc_auc_score(y_test, X_test['Age_binned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is higher than 0.5, so in principle Age does have some predictive power, although it seems worse than any of the categorical variables we evaluated before.\n",
    "\n",
    "Let's do the same quickly for Fare:\n",
    "\n",
    "#### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate the Fare values into 10 bins\n",
    "\n",
    "labels = ['Q' + str(i + 1) for i in range(0, 10)]\n",
    "\n",
    "# train\n",
    "X_train['Fare_binned'], intervals = pd.qcut(\n",
    "    X_train.Fare,\n",
    "    10,\n",
    "    labels=labels,\n",
    "    retbins=True,\n",
    "    precision=3,\n",
    "    duplicates='drop',\n",
    ")\n",
    "\n",
    "# test\n",
    "X_test['Fare_binned'] = pd.cut(x = X_test.Fare, bins=intervals, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test shows some missing data. These appear when the Fare values can't\n",
    "# be allocated to any of the calculated bins\n",
    "\n",
    "X_test['Fare_binned'].isnull().sum(), X_train['Fare_binned'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse as categorical variables\n",
    "\n",
    "X_train['Fare_binned'] = X_train['Fare_binned'].astype('O')\n",
    "X_test['Faree_binned'] = X_test['Fare_binned'].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857    0.492063\n",
       "52     0.533333\n",
       "386    0.354839\n",
       "124    0.730159\n",
       "578    0.396825\n",
       "Name: Fare_binned, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I create a dictionary that maps the bins to the mean of survival\n",
    "risk_dict = X_train.groupby(['Fare_binned'])['Survived'].mean().to_dict()\n",
    "\n",
    "# re-map the labels, I replace the bins by the probability of survival\n",
    "X_train['Fare_binned'] = X_train['Fare_binned'].map(risk_dict)\n",
    "X_test['Fare_binned'] = X_test['Fare_binned'].map(risk_dict)\n",
    "\n",
    "X_train['Fare_binned'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72538690476190471"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now, I calculate a roc-auc value, using the probabilities that we used to\n",
    "# replace the labels, and comparing it with the true target:\n",
    "\n",
    "# first I estimate a survival probability of zero for the missing data\n",
    "X_test['Fare_binned'].fillna(0, inplace=True)\n",
    "\n",
    "# then I calcualte the roc_auc\n",
    "roc_auc_score(y_test, X_test['Fare_binned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare, is a much better predictor of Survival.\n",
    "\n",
    "The authors mention that by using this method, you are able to compare directly numerical with categorical variables. In a sense this is true, however we need to keep in mind, that categorical variables may or may not (and typically they will not) show the same percentage of observations per label. However, when we divide a numerical variable into quantile bins, we guarantee that each bin shows the same percentage of observations.\n",
    "\n",
    "Alternatively, instead of binning into quantiles, we can bin into equal-distance bins.The way to do this, is to calculate the max value - min value range and divide that distance into the amount of bins we want to construct. That would determine the cut-points for the bins.\n",
    "\n",
    "To learn more on discretisation, visit my course \"Feature Engineering for Machine Learning\" also in Udemy. Get more details in the Final section of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
