{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid method: Recursive feature addition\n",
    "\n",
    "This method consists of the following steps:\n",
    "\n",
    "1) Rank the features according to their importance derived from a machine learning algorithm: it can be tree importance, or LASSO / Ridge, or the linear / logistic regression coefficients.\n",
    "\n",
    "2) Build a machine learning model with only 1 feature, the most important one, and calculate the model metric for performance.\n",
    "\n",
    "3) Add one feature -the most important- and build a machine learning algorithm utilising the added and any feature from previous rounds.\n",
    "\n",
    "4) Calculate a performance metric of your choice: roc-auc, mse, rmse, accuracy.\n",
    "\n",
    "5) If the metric increases by more than an arbitrarily set threshold, then that feature is important and should be kept. Otherwise, we can remove that feature.\n",
    "\n",
    "6) Repeat steps 2-5 until all features have been removed (and therefore evaluated) and the drop in performance assessed.\n",
    "\n",
    "\n",
    "I call this a hybrid method because:\n",
    "\n",
    "- it combines the importance derived from the machine learning algorithm like embedded methods,\n",
    "- and it adds as well one feature at a time, and calculates a new metric based on the new subset of features and the machine learning algorithm of choice, like wrapper methods.\n",
    "\n",
    "The difference between this method and the step forward feature selection we learned in previous lectures lies in that it does not add all possible features first, in order to determine which one to keep. It adds the most important one, based on the machine learning model derived important. And then, it makes an assessment as to whether that feature should be kept or not. And then it moves to the next feature.\n",
    "\n",
    "This method is therefore faster than wrapper methods and generally better than embedded methods. In practice it works extremely well. It does also account for correlations (depending on how stringent you set the arbitrary performance drop threshold). On the downside, the increase in performance assessed to decide whether the feature should be kept or removed, is set arbitrarily. The smaller the increase the more features will be selected, and vice versa.\n",
    "\n",
    "I will demonstrate how to select features using this method on a regression and classification problem. For classification I will use the Paribas claims dataset from Kaggle. For regression, the House Price dataset from Kaggle.\n",
    "\n",
    "**Note** For the demonstration, I will use XGBoost, but this method is useful for any machine learning algorithm. In fact, the importance of the features are determined specifically for the algorithm used. Therefore, different algorithms may return different subsets of important features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 133)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('paribas.csv', nrows=50000)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>...</th>\n",
       "      <th>v122</th>\n",
       "      <th>v123</th>\n",
       "      <th>v124</th>\n",
       "      <th>v125</th>\n",
       "      <th>v126</th>\n",
       "      <th>v127</th>\n",
       "      <th>v128</th>\n",
       "      <th>v129</th>\n",
       "      <th>v130</th>\n",
       "      <th>v131</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335739</td>\n",
       "      <td>8.727474</td>\n",
       "      <td>C</td>\n",
       "      <td>3.921026</td>\n",
       "      <td>7.915266</td>\n",
       "      <td>2.599278</td>\n",
       "      <td>3.176895</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.989780</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>AU</td>\n",
       "      <td>1.804126</td>\n",
       "      <td>3.113719</td>\n",
       "      <td>2.024285</td>\n",
       "      <td>0</td>\n",
       "      <td>0.636365</td>\n",
       "      <td>2.857144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.191265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.301630</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598896</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.957825</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943877</td>\n",
       "      <td>5.310079</td>\n",
       "      <td>C</td>\n",
       "      <td>4.410969</td>\n",
       "      <td>5.326159</td>\n",
       "      <td>3.979592</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>0.019645</td>\n",
       "      <td>...</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.477596</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>AE</td>\n",
       "      <td>1.773709</td>\n",
       "      <td>3.922193</td>\n",
       "      <td>1.120468</td>\n",
       "      <td>2</td>\n",
       "      <td>0.883118</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>8.304757</td>\n",
       "      <td>C</td>\n",
       "      <td>4.225930</td>\n",
       "      <td>11.627438</td>\n",
       "      <td>2.097700</td>\n",
       "      <td>1.987549</td>\n",
       "      <td>0.171947</td>\n",
       "      <td>...</td>\n",
       "      <td>7.018256</td>\n",
       "      <td>1.812795</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>CJ</td>\n",
       "      <td>1.415230</td>\n",
       "      <td>2.954381</td>\n",
       "      <td>1.990847</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677108</td>\n",
       "      <td>1.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target        v1        v2 v3        v4         v5        v6        v7  \\\n",
       "0   3       1  1.335739  8.727474  C  3.921026   7.915266  2.599278  3.176895   \n",
       "1   4       1       NaN       NaN  C       NaN   9.191265       NaN       NaN   \n",
       "2   5       1  0.943877  5.310079  C  4.410969   5.326159  3.979592  3.928571   \n",
       "3   6       1  0.797415  8.304757  C  4.225930  11.627438  2.097700  1.987549   \n",
       "4   8       1       NaN       NaN  C       NaN        NaN       NaN       NaN   \n",
       "\n",
       "         v8    ...         v122      v123      v124  v125      v126      v127  \\\n",
       "0  0.012941    ...     8.000000  1.989780  0.035754    AU  1.804126  3.113719   \n",
       "1  2.301630    ...          NaN       NaN  0.598896    AF       NaN       NaN   \n",
       "2  0.019645    ...     9.333333  2.477596  0.013452    AE  1.773709  3.922193   \n",
       "3  0.171947    ...     7.018256  1.812795  0.002267    CJ  1.415230  2.954381   \n",
       "4       NaN    ...          NaN       NaN       NaN     Z       NaN       NaN   \n",
       "\n",
       "       v128  v129      v130      v131  \n",
       "0  2.024285     0  0.636365  2.857144  \n",
       "1  1.957825     0       NaN       NaN  \n",
       "2  1.120468     2  0.883118  1.176472  \n",
       "3  1.990847     1  1.677108  1.034483  \n",
       "4       NaN     0       NaN       NaN  \n",
       "\n",
       "[5 rows x 133 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 114)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 112), (15000, 112))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target', 'ID'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test all features xgb ROC AUC=0.713140\n"
     ]
    }
   ],
   "source": [
    "# the first step of this procedure  consists in building\n",
    "# a machine learning algorithm using all the available features\n",
    "# and then determine the importance of the features according\n",
    "# to the algorithm\n",
    "\n",
    "# set the seed for reproducibility\n",
    "seed_val = 1000000000\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# build initial model using all the features\n",
    "model_all_features = xgb.XGBClassifier(\n",
    "    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "model_all_features.fit(X_train, y_train)\n",
    "\n",
    "# calculate the roc-auc in the test set\n",
    "y_pred_test = model_all_features.predict_proba(X_test)[:, 1]\n",
    "auc_score_all = roc_auc_score(y_test, y_pred_test)\n",
    "print('Test all features xgb ROC AUC=%f' % (auc_score_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x4fa50ca9e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIUAAAFxCAYAAADtdxgFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XnYZVddJ/pvVSqQRgoErcb2tt3KNSziYwstQYOEiCgO\nYAwOV25zmzaJXIwDQweHoA2tiEorMU7QkoS6gredI5BgJ6gdpyTECfTGlvww7U3HRsVIV0hIYkKF\n6j/2KXJy6h3WeWu/9Z6q/fk8Tx6os39n77X2XmvtdX7vHnYdOnQoAAAAAEzL7p0uAAAAAADHnqQQ\nAAAAwARJCgEAAABMkKQQAAAAwARJCgEAAABMkKQQAAAAwATt2ekCHHb77XcdWvzsMY95RA4cuGfT\n74rbetwql02cOHHHb9wql02cOHHHb9wql02cOHHHb9wql02cuDHi9u3bu2u9+JW+UmjPnpPEbXPc\nKpdNnDhxx2/cKpdNnDhxx2/cKpdNnDhxx2/cKpdNnLjtijtspZNCAAAAAGwPSSEAAACACZIUAgAA\nAJggSSEAAACACZIUAgAAAJggSSEAAACACZIUAgAAAJggSSEAAACACZIUAgAAAJggSSEAAACACZIU\nAgAAAJggSSEAAACACZIUAgAAAJigPTtdgEXnv+7aIz7bf9GzdqAkAAAAACcuVwoBAAAATJCkEAAA\nAMAESQoBAAAATJCkEAAAAMAESQoBAAAATJCkEAAAAMAESQoBAAAATJCkEAAAAMAESQoBAAAATJCk\nEAAAAMAESQoBAAAATJCkEAAAAMAESQoBAAAATJCkEAAAAMAESQoBAAAATJCkEAAAAMAESQoBAAAA\nTNCezQJaa7uTvDHJk5Lcl+RFVXXL3PKzk7w6ycEk+6vqstnnr0zyVUkeluSNVfXm8YsPAAAAwFZs\nmhRK8rwkp1TV01prZyS5OMk5SdJaOznJJUmemuTuJNe31q5MclqSL0jy9CSPSPLt21B2AAAAALao\n5/axM5NckyRVdWOS0+eWnZbklqo6UFX3J7kuyVlJvizJTUneluSqJO8cs9AAAAAAHJ1dhw4d2jCg\ntXZ5kiuq6urZv29L8viqOthaOzPJS6rq+bNlr0lyW5LPT/LPk3xlks9IcmWSJ1bVuhs7ePCBQ3v2\nnJSzX/GOI5ZddfE5W6kbAAAAwNTtWm9Bz+1jdybZO/fv3VV1cJ1le5PckeRDSW6eXT1UrbV/SLIv\nyd+tt5EDB+5ZtwC3337XhgXct2/vpjHiVmeb4sSJO/HjVrls4sSJO37jVrls4sSJO37jVrls4sSN\nEbdv3951ovtuH7s+yXOSZPZMoZvmlr0vyamttce21h6W4daxd2e4jezLW2u7WmufmuQTMiSKAAAA\nAFgBPVcKvS3Js1trN2S45Oi81toLkjyyqi5trV2Y5F0ZEkz7q+oDST7QWjsryR/MPv/Wqnpge6oA\nAAAAwLI2TQpV1ceSXLDw8c1zy6/K8DDpxe9951GXDgAAAIBt0XP7GAAAAAAnGEkhAAAAgAmSFAIA\nAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmS\nFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAA\ngAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkh\nAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACY\nIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIA\nAACYoD2bBbTWdid5Y5InJbkvyYuq6pa55WcneXWSg0n2V9Vls8/fk+TOWdj/X1XnjVx2AAAAALZo\n06RQkuclOaWqntZaOyPJxUnOSZLW2slJLkny1CR3J7m+tXZlkg8n2VVVz9yWUgMAAABwVHpuHzsz\nyTVJUlU3Jjl9btlpSW6pqgNVdX+S65KcleGqoke01n69tXbtLJkEAAAAwIrYdejQoQ0DWmuXJ7mi\nqq6e/fu2JI+vqoOttTOTvKSqnj9b9poktyX5/SRnJLk8yalJrk7Squrgets5ePCBQ3v2nJSzX/GO\nI5ZddfE5W6kbAAAAwNTtWm9Bz+1jdybZO/fv3XPJncVle5PckeT9Ga4gOpTk/a21DyX5J0n+ar2N\nHDhwz7oFuP32uzYs4L59ezeNEbc62xQnTtyJH7fKZRMnTtzxG7fKZRMnTtzxG7fKZRMnboy4ffv2\nrhPdd/vY9UmekySz28Bumlv2viSnttYe21p7WIZbx96d5PwMzx5Ka+1Tkzwqyd90bAsAAACAY6Dn\nSqG3JXl2a+2GDJccnddae0GSR1bVpa21C5O8K0OCaX9VfaC19uYkP9Nauy7JoSTnb3TrGAAAAADH\n1qZJoar6WJILFj6+eW75VUmuWvjO/UleMEYBAQAAABhfz+1jAAAAAJxgJIUAAAAAJkhSCAAAAGCC\nJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAA\nAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhS\nCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAA\nJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUA\nAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJmjPZgGttd1J\n3pjkSUnuS/KiqrplbvnZSV6d5GCS/VV12dyyf5zkj5M8u6puHrnsAAAAAGzRpkmhJM9LckpVPa21\ndkaSi5OckySttZOTXJLkqUnuTnJ9a+3KqvrgbNmbkty7HQU//3XXHvHZ/ouetR2bAgAAADjh9Nw+\ndmaSa5Kkqm5McvrcstOS3FJVB6rq/iTXJTlrtuz1SX46yV+PV1wAAAAAxrDr0KFDGwa01i5PckVV\nXT37921JHl9VB1trZyZ5SVU9f7bsNUluy3Ar2T+tqte21n47yQWb3T528OADh/bsOSlnv+IdRyy7\n6uJzjvisNw4AAABgwnatt6Dn9rE7k+yd+/fuqjq4zrK9Se5I8tIkh1prX5LkyUne2lr7qqr62/U2\ncuDAPesW4Pbb7+oo5uZx+/bt7VrXlOJWuWzixIk7fuNWuWzixIk7fuNWuWzixIk7fuNWuWzixI0R\nt2/f3nWi+5JC1yc5O8kvzZ4pdNPcsvclObW19tgkH8lw69jrq+pXDgfMXSm0bkIIAAAAgGOrJyn0\ntiTPbq3dkOGSo/Naay9I8siqurS1dmGSd2V4PtH+qvrA9hUXAAAAgDFsmhSqqo8luWDh45vnll+V\n5KoNvv/MrRYOAAAAgO3R8/YxAAAAAE4wkkIAAAAAEyQpBAAAADBBkkIAAAAAEyQpBAAAADBBkkIA\nAAAAEyQpBAAAADBBkkIAAAAAEyQpBAAAADBBkkIAAAAAEyQpBAAAADBBkkIAAAAAEyQpBAAAADBB\nkkIAAAAAE7Rnpwuw3c5/3bVHfLb/omftQEkAAAAAVocrhQAAAAAmSFIIAAAAYIIkhQAAAAAmSFII\nAAAAYIIkhQAAAAAmSFIIAAAAYIIkhQAAAAAmSFIIAAAAYIIkhQAAAAAmSFIIAAAAYIIkhQAAAAAm\nSFIIAAAAYIIkhQAAAAAmSFIIAAAAYIIkhQAAAAAmSFIIAAAAYIIkhQAAAAAmSFIIAAAAYIIkhQAA\nAAAmSFIIAAAAYIIkhQAAAAAmSFIIAAAAYIIkhQAAAAAmSFIIAAAAYIIkhQAAAAAmaM9mAa213Une\nmORJSe5L8qKqumVu+dlJXp3kYJL9VXVZa+2kJJclaUkOJbmgqv5sG8oPAAAAwBb0XCn0vCSnVNXT\nklyU5OLDC1prJye5JMmXJvnCJC9urT0uydlJUlVPT/LvkvzAyOUGAAAA4Cj0JIXOTHJNklTVjUlO\nn1t2WpJbqupAVd2f5LokZ1XV25O8eBbzz5PcMV6RAQAAADhauw4dOrRhQGvt8iRXVNXVs3/fluTx\nVXWwtXZmkpdU1fNny16T5Laqunz277ck+eokX1dVv77Rdg4efODQnj0n5exXvOOIZVddfM4Rn40d\nBwAAAHAC2rXegk2fKZTkziR75/69u6oOrrNsb+auCqqqb2itfVeS32+tfVZV3b3eRg4cuGfdAtx+\n+10dxRwvbt++vV3rOhHiVrls4sSJO37jVrls4sSJO37jVrls4sSJO37jVrls4sSNEbdv3951ovtu\nH7s+yXOSpLV2RpKb5pa9L8mprbXHttYeluSsJO9urb2wtfbKWcw9ST42+w8AAACAFdBzpdDbkjy7\ntXZDhkuOzmutvSDJI6vq0tbahUnelSHBtL+qPtBa+9Uk/09r7XeTnJzk5VV17zbVAQAAAIAlbZoU\nqqqPJblg4eOb55ZfleSqhe/cneTrxyjgsXL+66494rP9Fz1rB0oCAAAAsP16bh8DAAAA4AQjKQQA\nAAAwQT3PFGKO28wAAACAE4ErhQAAAAAmyJVC28QVRQAAAMAqc6UQAAAAwARJCgEAAABMkKQQAAAA\nwARJCgEAAABMkKQQAAAAwARJCgEAAABMkKQQAAAAwARJCgEAAABMkKQQAAAAwARJCgEAAABMkKQQ\nAAAAwARJCgEAAABMkKQQAAAAwARJCgEAAABMkKQQAAAAwARJCgEAAABMkKQQAAAAwARJCgEAAABM\nkKQQAAAAwARJCgEAAABMkKQQAAAAwATt2ekCTN35r7v2iM/2X/SsHSgJAAAAMCWuFAIAAACYIEkh\nAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACY\nIEkhAAAAgAmSFAIAAACYIEkhAAAAgAmSFAIAAACYoD2bBbTWdid5Y5InJbkvyYuq6pa55WcneXWS\ng0n2V9VlrbWTk+xP8ulJHp7ktVV15fjFBwAAAGAreq4Uel6SU6rqaUkuSnLx4QWz5M8lSb40yRcm\neXFr7XFJ/nWSD1XVM5J8eZKfGrvgAAAAAGxdT1LozCTXJElV3Zjk9LllpyW5paoOVNX9Sa5LclaS\nX07yqlnMrgxXEQEAAACwInYdOnRow4DW2uVJrqiqq2f/vi3J46vqYGvtzCQvqarnz5a9JsltVXX5\n7N97k1yZ5LKq+rmNtnPw4AOH9uw5KWe/4h1HLLvq4nOO+GxqcQAAAABbsGu9BZs+UyjJnUn2zv17\nd1UdXGfZ3iR3JElr7dOSvC3JGzdLCCXJgQP3rLvs9tvv6ijmdOL27dvbta6euDHXJU6cOHHHQ9nE\niRN3/MatctnEiRN3/MatctnEiRsjbt++vetE9yWFrk9ydpJfaq2dkeSmuWXvS3Jqa+2xST6S4dax\n18+eK/TrSb6tqv5LxzYAAAAAOIZ6kkJvS/Ls1toNGS45Oq+19oIkj6yqS1trFyZ5V4bnE+2vqg+0\n1n48yWOSvKq1dvjZQl9RVfduQx0AAAAAWNKmSaGq+liSCxY+vnlu+VVJrlr4zsuSvGyMAgIAAAAw\nvp63jwEAAABwgpEUAgAAAJignmcKsQLOf921R3y2/6Jn7UBJAAAAgBOBK4UAAAAAJkhSCAAAAGCC\nJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAA\nAGCCJIUAAAAAJmjPTheAcZ3/umuP+Gz/Rc/agZIAAAAAq8yVQgAAAAAT5EqhiXJFEQAAAEybK4UA\nAAAAJsiVQmzIFUUAAABwYnKlEAAAAMAESQoBAAAATJCkEAAAAMAESQoBAAAATJCkEAAAAMAEefsY\no/CWMgAAADi+uFIIAAAAYIIkhQAAAAAmSFIIAAAAYII8U4hjyrOHAAAAYDW4UggAAABggiSFAAAA\nACZIUggAAABggiSFAAAAACbIg6ZZSb0PpB47DgAAAKZCUgjmSB4BAAAwFZJCsAWSRwAAABzvJIVg\nG7m9DQAAgFXlQdMAAAAAEyQpBAAAADBBbh+D44jb0QAAABiLK4UAAAAAJmjTK4Vaa7uTvDHJk5Lc\nl+RFVXXL3PKzk7w6ycEk+6vqsrlln5/kP1TVM0cuNwAAAABHoef2seclOaWqntZaOyPJxUnOSZLW\n2slJLkny1CR3J7m+tXZlVX2wtfadSV44+xxYQW4zAwAAmK6epNCZSa5Jkqq6sbV2+tyy05LcUlUH\nkqS1dl2Ss5L8cpL/luRrkvzsqCUGjimJIwAAgBNTT1LoUUk+PPfvB1pre6rq4BrL7kry6CSpqita\na5/eW5DHPOYR2bPnpDWX7du3t2sd4sSJOzZxa8Wc/Yp3HPHZVRefs+W4rZRL3GrFrXLZxIkTd/zG\nrXLZxIkTd/zGrXLZxInbrrikLyl0Z5L5Ne6eJYTWWrY3yR3dW59z4MA96y67/fa7utYhTpy4YxN3\nLLa5nW9a27dvb1fZxG09bpXLJk6cuOM3bpXLJk6cuOM3bpXLJk7cGHEbJYl6kkLXJzk7yS/Nnil0\n09yy9yU5tbX22CQfyXDr2Os71glwTG1nkgkAAOB41JMUeluSZ7fWbkiyK8l5rbUXJHlkVV3aWrsw\nybsyvN5+f1V9YPuKC7AaJJkAAIDj3aZJoar6WJILFj6+eW75VUmuWue7tyY54yjKBzAJYyeZJKMA\nAIDN7N7pAgAAAABw7EkKAQAAAExQzzOFADhB7dRta26XAwCAnScpBMBkSDIBAMCDJIUAYItc8QQA\nwPFMUggAjjOSUQAAjMGDpgEAAAAmyJVCAECXMa88cnUSAMDOkxQCAFaWW+AAALaPpBAAMBmexwQA\n8CBJIQCAbSZ5BACsIkkhAIAV4QolAOBYkhQCADhB7dTtcpJWAHB8kBQCAGBHSB4BwM6SFAIAYKW5\nkgkAtsfunS4AAAAAAMeeK4UAAGANq/5MJlc8AXC0JIUAAOAEJnkEwHokhQAAAFcyAUyQpBAAALBj\nxkwySVgBLEdSCAAAYA2r/rwoyS3gaEkKAQAAnMAko4D1SAoBAAAwOskjWH2SQgAAAOwYt9/BzpEU\nAgAAgHWsetJKcoujsXunCwAAAADAsedKIQAAADjBuaKItUgKAQAAAElW/zY4ya1xuX0MAAAAYIIk\nhQAAAAAmyO1jAAAAwAllzNvRTuRb21wpBAAAADBBkkIAAAAAE+T2MQAAAIBjZJVuR3OlEAAAAMAE\nuVIIAAAA4Dh1NFcUuVIIAAAAYIIkhQAAAAAmSFIIAAAAYIIkhQAAAAAmaNMHTbfWdid5Y5InJbkv\nyYuq6pa55WcneXWSg0n2V9Vlm30HAAAAgJ3Vc6XQ85KcUlVPS3JRkosPL2itnZzkkiRfmuQLk7y4\ntfa4jb4DAAAAwM7rSQqdmeSaJKmqG5OcPrfstCS3VNWBqro/yXVJztrkOwAAAADssF2HDh3aMKC1\ndnmSK6rq6tm/b0vy+Ko62Fo7M8lLqur5s2WvSXJbkjPW+872VQUAAACAXj1XCt2ZZO/8d+aSO4vL\n9ia5Y5PvAAAAALDDepJC1yd5TpK01s5IctPcsvclObW19tjW2sMy3Dr27k2+AwAAAMAO67l97PCb\nxD4nya4k5yX53CSPrKpL594+tjvD28fesNZ3qurm7asGAAAAAMvYNCkEAAAAwImn5/YxAAAAAE4w\nkkIAAAAAEyQpBAAAADBBkkIAAAAAE7RnpwuwSlprX1pVv77T5dhOrbVTMrwV7hOS/H2SP6uqUZ42\n3lr75CQfOpr1tdY+O8k/VNUtc599flX9/hhlPJFttf221r4wyceq6ve2oVgrZSJ9fKX7UGvt5Axj\n0KOT3JFhDLr/GGz3k6rqQ621z0zy5CR/XlV/vt3b7bXsfpm95fOfJPmbqvrYsSll0lrbNdY5Y26d\n645B23nOOh601h5eVfcdw+2dnuQTq+o3j9U2l7Fe+aYwtrPzWmsPS3JSVd278PmjqurOTb67t6ru\nmv3/z07ypCTvqar3bVuBH9z2Sp//eu3E+WCrx613TGqt/eOq+rujLOMJcXznreK5aKfmr8fKyrx9\nrLV2TpIvyYM7+veS/MpiZ++N69zmixc+ujDJjyZJVV06F7cvyUVJ7k1ySVV9aPb5v6+q79tg/T9a\nVRd2lGPduJ76zn4cnJ3kw0n+NMklSR5I8t1V9cG5uOcmeU2Sv0jyBUluTPJpSb6jqq5b2O4LkpyZ\nBwfe36iqaxZizpt9/51Jfi7JPyR5RJJvWWPC1rO+VyX5siQnJ3nPbD2HWmvXVtWz5uJ+LsnLewbR\nzu1+RpInJvntDMf5KUn+a5IfrKoPz8V1t4PZvv7obJ0/muQTMxyP27ZYj5713ZvkV5K8rKr+5wbr\n+j+SXDyrx/+b5AuT3Jfk3VX12vm4qvrl1tonJPneDCeaP07y2qr6yFzcw9bb1vxg2bv/etrzEuvq\n6uOz2E3byiyu51j0lq93H/fGdfWhWWzP2NK73d4+9NwkP5RhDPpIkr2z7313Vb19G/fzTyW5NckH\nk/zbJL+b5IxZfV+/hXp0990evfultfbmqvrG1trnJ/lPST40iz2/qm5cWGfP2NdVj9ba/57kDUlO\nS/KpGdrAXya5sKr+do26bHbceseg7nNWr852v2kdlqhr7z4+O8lPzdb3PVX1i7PPj+i7W7HePKO1\n9rwkP5ZhjP2JJF+dYb9UVX3XQuyY86/e80ZX+ZY4/3X18Vls7zmhp6911XcWO2a76p0fdsXNYsec\nl459Dhz1+LbWnpDkB5Pcn6H9vTXDH9RfebiPzuLuSfKSqnpz1nG4L8/mzt+S5NrZ9t+y8Juju60s\nrH+9Pt51/uu1xLEYte1t9XywwX7p3W7vcev9TfmEhbi3Jvk3s7j3L5Sxp6+NOr/Zqg32c+9Y1TvW\nd49VI5evd57WOy/tnW/29reuectGVuJKodbaGzLcynZ1krsy7OivyPDj5kVbiFvsmB+38EPweRl2\n2jVJdiV5eIa/vC56a5K3Zdhfv9tae05V/fcME9n5etww989dSU5rrZ0x2+4XbCGuq75JLp+t51OS\nfFKSN83iL8/QcQ77jiRfUFX3tdY+KUOn+7Ikv5bkGXPb/fEMne3KPNjxntNae3pVvWpufd+S5Jmz\nuK+qqve31j41yTuS/OYW1vecqnra7Ds/kuFHyLfM6jbvaUmuaa39ZJKfWW9CusR235rkVUl+PMlf\nJfl3Sc7KkOh67kJcTzu4PMkpGY7X9yX52SR/neSyDPt72Xr0ru/GDPv+91prv5Tk8qr6wBqrfEWS\nz8rQ1m+Y/e8DSa5L8tq5uG9O8suz/fKXSV6a5IuTXJrkBXNxNyV5XJL/meFYHZr738fPxXXtv/S1\n5951dfXx3rayxLHoLV/vPu6N6+pDS4wtvdvt7UPfk+TMmvuLamvt0RnGi/mT6tj7+SlV9W2ttd9N\n8oyquru1tifJu5O8fmF9PfXo7bu/laHNzduV5ND8WN+7X5J8xux/fyDJV1TVX8zG3J+fr/MSY19X\nPTK0o5fOxvgzkpyT4Qf4m+f3yxLHrXcM6j1ndZ3ze9p9bx3GHucztIEnz8r3y621U6rqLTmy7/bW\ntWuekeSVs+0+MskfJflnVXV/a+36he2OPf/qPW90lS/957+uPr7EOaG3r3XVdxvaVe/8sCtuG+al\nY58DRz2+Gfb792f4Uf7ODFeJ3JFhbP7Fubg/TfIvW2vXJvm+qvqdrO8bk3xRVX2kDVce/NasHof1\ntpXePt51/lui7/Yei1HbXvrPB737pXe7h2123Hp/U/5mknsy9OtdSdps24eSzP8BvLevjTq/2YZz\nTO9Y1TvW945VY5evd57WOy/tnW9u2t+WOG9saCWSQkk+u6oWd9aVazSE3rgnZmgYP5uHTqgWD/Rz\nM0xA9yT590meWWtf+fPwwx2htfYnSd7RWntmjkxW/FSS85O8LMndGSbq/2qN9fXG9db31Kp6Rhv+\nuvBnh/9S0Vr7poW4Ryc5fJvBP2TocHe21hZ/tDx5brvXtNZ+o6qe3VpbzMR/dDb43JWhoaaq/rq1\ntrife9f38f1ZVd/RWvtPrbXvyJHH7dYMGeTvS/L/zbK8Vyf5y3ro5bu9232gqn67tfY9VXV4MPyT\n1trXL8T1toMnVNVZrbVdSf5rVb1x9p2XbbEeves7VFW/0lr7zxlOXlfM2sStVfU1c3G7k9wz+0H5\nvVV1cLa+9Z4xdmpVHT4Bva+19jULy89M8q4kX1xVB9ZZR9K//3rac++6evt4b1vpPRa95Zuv80b7\nuDeutw/1ji292+3tQydnmAzNu3eN8o2+n1trj80wTj0iw7j7qDXieutxa/r67kUZTspfneTgYpnm\n9O6X+XL+RfLxMXex7/a25956PLpmf8Gsqhtbaz9cVa9srT1mYX29x613DOo9Z/We83vafW8dxh7n\n7z88frbhr8PXttZuW6MOvXXtnWeclGFCnQz7+tDc5/PGnn/1njd6y9d7/uvt4719qDeut75jt6ve\n+WFv3Njz0vn4Mc6BYx/fPVX1m7Pj8YOHE42ttY8uxN07+2F+epJXtuHqjf+S4Xj8xCxm7+w89Ld5\n8HxwMMnilUG9baW3j/ee/3r77mGbHYux217v+aB3v/Rut/e49c43T0/y00n+Y1X9Rmvtt6rqi9aI\n656njTy/Gfscc2v6xqresb73uI1dvt55Wu+8tPd4zNd7vf7We97Y0KokhXa31p5Rc88TaK2dleEy\nqKXjqurC1toTk1xdVX+43kZryAZ+T2vtazP81fOUdUL3tNb+RVXdVFU3tNZ+KMNfFx65sL6fa629\nL8kPZ7hx/aj1AAATA0lEQVRs8N4asoOL2+2K663v7POnV9X1rbUvmf37M3PkX6h/IckftNZ+O0M2\n8g2zBvOehbhT2uwZJK21ZyQ5OJv8f8JC3JWttXdk+KvGO1tr78qQxb52i+v7xdbaHyT58hou/z4/\nw34+YyHuUFXdkeRlbbhM7+syZFufkORfbGG7d7TWvi7Jr7XW/k2Sq5I8J0d2/q52kOTk1tqXJfnk\nJI+btcW7MgwoW6lH7/p2JUlV3ZPkJ5P8ZGvtUbP1zXtLhoHnyVX1hiRprV2RYRCc94TW2r9N8tHW\n2r+sqvfOJjwPORFW1e2ttYuSfG6GSdB6evdfT3vu7ZO9fby3rfQei966du3jJeJ6+1Dv2NK73bX6\n0HNzZB+6NMl7ZhPvD2eYuJyZ4S9+88bez69J8jsZxqo/ba39YZLPzvCXqa3Uo6vvztrTzyb5nKp6\nW9bXu18e3Vr74ySPaK19Y4ZbyC5Osnh5cG977h2D/rK19tMZxoivTPJHbbhU+e6F9fUet/XGoP+8\nENd1zuo956ev3ffWYexx/tbW2o8meVVV3TWb8L0rw1+el67rEvOMn8/wY+LWDH/5vqYNt2It3iY1\n9vyr97zRW77e81/v+b63D3XFLVHfsdtV7/ywN27seenY58Cxj++trbVfyPB76SOttR/IMEb/zULc\n4fb3R0m+tg1XEJyV4SqQw67PcDXbqUkubK39xOyzt86vqLetLNHHu85/S4yjvcdi7LbXez7o3S+9\n2+09bl3zzar6uzb88P+R1tpT14qZ6e1rRzO/OaJvbMM5pnes6h3ru47bNpSvd57WOy/tHat6+lvv\neWNDq5IUOjfJj7bWfj7DwPpAkvcm+b83iEuGTOJacclwf+YRPzbXUlVXtNYqyQvXCXlphgnG86vq\ng1X1i224dPDH11jXe2cH9/Ik+zbY5ntbay/McPn9enHnpq++35TkB1prN9SD9w5enOFSy/lt/ofW\n2q9leC7Em6rq5tbaJ1fV3y+s74Ikl7bW/mmS/5bhh+W5GTrJ/Ppe14YHhH5XhsHyT5P8WFUtTuy/\nOcmbOtZ3SWvt7Rk6W2p4uOaXteE+03kfnPvO7Un+4+y/RV3bzbA/fzjJ05N8eoZ7y6/LQy/PTPrb\nwQUZ/krw3iTfmmGw/lCOPG699Ti8vvcsrG+xfC9f/OIsy/1HC5+9obX2C/XQh9O+shbuZc7w4+8p\nSd6f5HNaa3+ZIfN+wRrb6XnAZ+/+W689f/sW1nW4fJv18a42n6FNvTqbH4ve8vXu4664JfrQuXno\n2HJoVqfFNtpbvsU+9KEM974/ZL9U1WWttSuTfF6GE+qHk7ymjrwPvLcPde3nqrq6tfZ7GZ5D8M7Z\nut4z63cb1WO9saC376aqfqS19vbW2n0ZJllH/NV1jf1y51r7paqe0oYHbf5qhgnnAxkmgovPsegd\n+3rrcV6GffNNGRI3b8rQLv7PNba7Vv94yHHrHYOWOGclfef8c/PQucbHcmS7n29735b1+/jY4/z5\nSf51kre31i7JkIB7ZpLvXiO2a37TM8+oqovbcOn54QTfVyQ5UEc+o+PcjDz/6jlvLFG+rvNf+vt4\n7zmhN673PNnVh9LfrrrmhxvEfftC3Lnpm6/3rm/Uc2D6j2/vGPkNGf4w8M0ZntPxlAw/2s5fiPuZ\nJJmdf9+U5JqquirDD70kSVW9fBazK0Py6Z4kz6+qmxfW1dtWun5zLHH+S/r6bu+x6G0DW/kN89NV\nVeudDzp/Y/Vud/64PSIbHLdZ/BWttZuz/nwzVXWwDc+UuSXrvwn83HT0taOY36w5T5tZ5hyz2W/e\nrrFqibG+t131toPe8s3P0/ZmnXla+uf/vWNVT3/r/Z24oZV50PRhrbWTMtyD+dc18htV2shv8Wit\n7V6vjG24DP7pSf5go23O4p6ySVb+cOzj1mh8G8U/pL6zDOh3ZbjssuuB2a3jTTOttadkOEGemeE+\nyjdX1V9tEL/uW8raFh5k2dZ5G8Qacf8owxtuRmkDbfbGgI3awSzuERkuE9ysHRzVm4Ra/8PNlm4H\ns+XrvXVjqw99e1iGy0Lvm69z63uLx5oxi8eid5/06inbGt/5eB/qGDO62sB6bfkoju3Dk+zu6ENd\nb8lYb31bbSvz692kH/2jDD9WP7pGO9jKfunpu71j5HkZxsi3J9lfRz4wu7t8c+t7RjYZc2fn1E/J\nEmPLevt5jXpsNtbvS/L3Y431Y9ps3J7FdL9pbYk+tOF5aLO2skb8pue/WcznJ7n+KM4vS499s+8d\n9fn+WLSVjrGld+zrmo90lml3hge7HzEfPorj0TUP6q3vXPy6+2+ZftSzvtnyrrfdHu28ee7zrjF3\nmbF5gzJsZa6+O0NS4I/XanuzPvTsDH902LQPjTEn3aqN+tAW6/H06ni77rEeq9ZoK5uN9eueT5fV\nc/6bi910LFjyt+ya+/ko2v2m7XQW97kZ+sfRvCF7qfY3+84nZ0jQ7Fr2t84a6+oaS5cd9w5biaRQ\ne/CNKp+XB9+o8qgk59UWXqPcOt/i0fofqta73c/K8JaCAxnqcXmGHzwvq6p3bmF9az2h/oUZGtb7\n5+J663t1Hnz41bdmeCjtf18j7vCbZp6Y5H/LBm+aWSjvYzJkV7+6qh4+9/l56XhLWVv/oWon14P3\nUR7eLz1vg/isDA9kvSPH9nh0tYO2xJuEOsvXe3x743r38/6s/dC3F1bV2VtYX89bPDaNWaauvZbY\nbtfbmjZoAw8Z+5ZoU2Mf2942P3Zb6R3Tuvr4Evuldz93v41r3gZj5Jba6Qbrmz+n/lzWb1dfOavH\nUm+8WmKsvzfDX8S3OtaPfY7e9Ny2RN9d5jy0Vpt6eQ1XEqxX1vX2ce92u84vvft4ibFv7PP9qG1l\nibFl7LGvt3yLx+3vs8Z8eInj0TtGjj3f7O1HvevrbVej1mON/blmv+yJW6INjH0e7+1Do85Je21D\nPdZqA0e83Wunxqo16n+059PedtX1226J/dfbx3v3c2+77503d2231xLtoLe+y/6e2Gje0jXubWZV\nbh/7jNn//mCGRrDeG1WWeZPLpm/xSOfDtJbY7k9nuPT00zPcT/qEDI3h6gyNY9n1rfWE+kuz8IT6\nJerb+/CrrjfNzNXnGRkuc3xqhiekL17C1/WWsvQ/VK33bRA7dTy6tpv+Nwn1lq/3+PbG9e7n3oe+\njfkWj943fXTVdYl93Lvd3j7U1QbS36a2emyfnOFH6+Kx6G3zvevrbSu9Y9rY+6V3fWOPkUs9mLxj\nffPn1I3a1b9L337u3e7YY/3Y5+jF4/a8WT3mj1tPTNLf5jdqU0ckhTr2ce842ju29D5UtHfsG7sN\njP2A696xZatj33rHo7d8vcet93j0jmljzzd7x8je9fW2q7HrkaSrX/bE9baBsedovX1o1DnpEuPy\n2PXoertXdm6sSjLq+bS3XfWe23r3X28f761Hb7vvHSN735Dd2057j29vfcf8PdE77m1ovfsYd8pD\n3qiSI8t3UYZ7HF+Y4Qni/yrDMw0WnyZ+f1UdqOHSs3OSfFtr7Yuy0EGq6sIkf5HhOQ/fN/ffa7a4\n3d1V9TuzE8vbq+rvarg0bPGtM73rOz3Jnyf5oRqeTP8nVfVFa/wVo6u+mT38alb3G5IcfvjVoxfi\nHvKmmQyXXv5xksU3zRz28gwDy5Oq6vur6n8sLP9oVd2dIbP68beUrVG+3bNB8uPa2g9V2zPLtv5q\nhksQPzBb/xEPJt+h49G73cPGave9x7c7rnM/pw0Pfbs/w2WzaWs/rK93ffdW1bcl+c4kL22t3dRa\n+7HW2kuXjFmmrr37uHe7y/ahzdpAb5va6rH9H+sci94237u+3rbSO6aNvV961zf2GNlbvt71HbZZ\nu+rdz73bHXWs34Zz9OJx+4I1jltPTNLf5pc9H2zaVnrH5ZkN28AS+7h37Bv7fD92W+lt81sd+9Y8\nHkuU77DN+m7v8ehtf2PPN3vHyN719barsetxWO+Yu27cEm1g7Dlab187bKw5affcdeR69LaBHRmr\n5oxyPl2iXfWe23r3X28f793Py86DNmunvdvt/o3feXx7tzvm74neY7ahVblSqOuNKtX/JpdbW8db\nPGY2fZjWEtutNjwk68VVdW6StOENAg+5naB3fdX/hPre+vY+/Kr3TTOHy/m1G5Qt6X9L2bnpe5Dl\nra3vbRA7dTy6tpvx233v8e2N693PvQ99613frlm9N3qLR09Md12X2Me92+3tQ71vk+ptU6Me2yXH\noLHbSs+YNvZ+6V3f2GPksg9O32x9ve1qmXPlToz1ybjn6J7j1ntsRz0PzdVls33cu93eNpD0PVS0\nd+wbuw30xvXWo6vNb8PY11u+3uPWezx650FjzzeX6Uc96+tqV9tQj8Pr3axf9sb1tIGx52jnpq8P\njTonXfI322j1WKIN7ORYNeb5NOlrV119con919vHe+vR2+57x8jeMaO3nZ6bvuPbW9/Rfk8sccw2\ntBLPFEqS9uAbVX4twyVP35jhAW1r/aX57bOYNd/k0lrbk+EtHv9XhgeZXp3hqePfXbOnyG+xjJtt\n9/BDVM+dxV0zK8Ov1vCa1KXWtxD3G0m+vo68dO2o69uOfDjvwzI08ufmoW+a+YuaPfhrWe3Bt5S1\nDJe9/U4d+Zay3nXtyYNvg/jZWdk+lOHNZ3fPxe3U8eje7pjtfoPydj1Qbo120LWflyhH73H7hqp6\nS3voWzwWbxfZNGaZus59vlkf79ruMn2opw0s25Y3q++yx7ZzDBq7rWw6pm3Dfula33aMkT3lW/K7\nPe1q9HPlmGP9Fra9Wf/d9Lj1HtvtOg911LG7ry1zfunYbveYu5NtYDPLtvljPfbN1tnTd3vPRVuZ\nBx31fHPJftR1PJZpV9s9b94J2z1Hm61z9Dlp52+2Uesxt91128AsZmXHqmT0305LzVs6+tAy89wt\n12OteVBvO93CmLH0b6x11rXpdrfp98SmbX4jK3P7WFX9Q4b7nk/L8ArRT5n9t5bvT/KcJO9trX1v\na+2fLazrYFX9TIZLwp6TIZP3LRleJ3k0Ntvux6rqHUlem+HgvTfJZ2Z4oOrS61uIOy3JJ25HfRc7\nW1XdX1VvyHA8npjkD5N8eYYHZW1JDfdKvirDhOTLk3xea+3Ttriug7P9/D1Jnpbki5OcnOSxC3E7\ndTy6tztmu19P74/KNdpB137utcRxe8vs/35/hv33J7P6ftoyMZuUZb19slkf79ruMn2opw1soS1v\nWN8tHNueMWjstvIz2WRM24b90rW+7Rgje8q35Hd72tXo58oxx/ot2Kz/bnrceo/tNp6HNrRMX1vy\n/LLZdrvH3B1uAxvaQps/pmPfbJ09fbf3XLSVedBRzzeX7Eebrm8Wu0y72tZ5807Y7jnabJ3bMSft\n+c02aj3mtrtuG5hte2XHqmT0307Lzls260PLzHO3XI+15kG97XQLY8bSv7HWKfOm292O3xPpaPMb\nWZkrhea1o3i6/zJxrf/hUjtSvrHjtru+vRyP7Ynr3X9j7+dVOG6rXLZjGbfq9d2p8q3Kftng+1sq\n3xLrPyb16F3fTo1VW4nbqT7e63jtG2O3gVVoKxvFrXr5xI3bL9fZxmTnaGPEnShj1Vat2n4ZO27V\n67Hq5dvKuhatyjOFkiRtnKf7LxN3UYan3n911n/o406Wb+y4balvL8djZY7v2Pt5x47bKpdth+JW\nvb47Vb4d3S8dlipfrx2oR+/6dmqs6o7bqT7e6wToG2O3AWOfuG2LG8nk5mgjx50oY9VSVni/jB23\n6vVY9fId9Xi2UkmhDE9ivyzJi2rj+/lGiav+h0vtSPnGjtvG+vZyPLYxrnf/jb2fd/i4rXLZjnnc\nqtd3p8q3AvtlQ1soX69jWo/e9e3UWLVk3E718V7Hdd8Yuw2sQB9fyf0s7pj3y3VNdI42WtyJMlZt\nwUrul7HjVr0eq16+Jde1ppW8fexYayM+XOp4sOr1XfXyrbre/Tf2fl7l47bKZdsOq17fnSqf/bJa\ndmqs4kir3idPlLay6uVj+5mjHZ0TZazaqfKtulWvx6qX72iszIOmd9hoD5c6Tqx6fVe9fKtulIf/\nbeN2d8Iql207rHp9d6p89stq2amxiiOtep88UdrKqpeP7WeOdnROlLFqp8q36la9Hqtevi1zpdCc\ndgweNLdKVr2+q16+Vde7/8bez6t83Fa5bNth1eu7U+WzX1bLTo1VHGnV++SJ0lZWvXxsP3O0o3Oi\njFU7Vb5Vt+r1WPXybcWqPVNoR7Rj+6C5Hbfq9V318q263v039n5e5eO2ymXbDqte350qn/2yWnZq\nrOJIq94nT5S2surlY/uZox2dE2Ws2qnyrbpVr8eql+9oSAoNjtmD5lbEqtd31cu36lb9wac7YZXL\nth1Wvb47VT77ZbWs3MNgJ2zV++SJ0lZWvXxsP3O0o3OijFVjc3yPjVUv35a5fQwAAABggjxoGgAA\nAGCCJIUAAAAAJkhSCAAAAGCCJIUAAAAAJkhSCAAAAGCC/hceMc9t4qvw7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4fa06e2588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the second step consist of deriving the importance of \n",
    "# each feature and ranking them from the most to the least\n",
    "# important\n",
    "\n",
    "# get feature name and importance\n",
    "features = pd.Series(model_all_features.feature_importances_)\n",
    "features.index = X_train.columns\n",
    "\n",
    "# sort the features by importance\n",
    "features.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# plot\n",
    "features.plot.bar(figsize=(20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v50',\n",
       " 'v10',\n",
       " 'v21',\n",
       " 'v114',\n",
       " 'v12',\n",
       " 'v34',\n",
       " 'v14',\n",
       " 'v40',\n",
       " 'v23',\n",
       " 'v129',\n",
       " 'v99',\n",
       " 'v6',\n",
       " 'v69',\n",
       " 'v102',\n",
       " 'v87',\n",
       " 'v39',\n",
       " 'v16',\n",
       " 'v42',\n",
       " 'v38',\n",
       " 'v57',\n",
       " 'v18',\n",
       " 'v127',\n",
       " 'v123',\n",
       " 'v85',\n",
       " 'v131',\n",
       " 'v82',\n",
       " 'v73',\n",
       " 'v72',\n",
       " 'v124',\n",
       " 'v19',\n",
       " 'v78',\n",
       " 'v92',\n",
       " 'v55',\n",
       " 'v35',\n",
       " 'v122',\n",
       " 'v80',\n",
       " 'v45',\n",
       " 'v86',\n",
       " 'v130',\n",
       " 'v28',\n",
       " 'v32',\n",
       " 'v126',\n",
       " 'v36',\n",
       " 'v97',\n",
       " 'v1',\n",
       " 'v120',\n",
       " 'v5',\n",
       " 'v59',\n",
       " 'v27',\n",
       " 'v9',\n",
       " 'v68',\n",
       " 'v103',\n",
       " 'v119',\n",
       " 'v11',\n",
       " 'v90',\n",
       " 'v98',\n",
       " 'v88',\n",
       " 'v37',\n",
       " 'v2',\n",
       " 'v81',\n",
       " 'v54',\n",
       " 'v118',\n",
       " 'v70',\n",
       " 'v61',\n",
       " 'v101',\n",
       " 'v108',\n",
       " 'v117',\n",
       " 'v26',\n",
       " 'v49',\n",
       " 'v89',\n",
       " 'v111',\n",
       " 'v58',\n",
       " 'v77',\n",
       " 'v33',\n",
       " 'v43',\n",
       " 'v20',\n",
       " 'v93',\n",
       " 'v25',\n",
       " 'v65',\n",
       " 'v46',\n",
       " 'v29',\n",
       " 'v8',\n",
       " 'v7',\n",
       " 'v115',\n",
       " 'v121',\n",
       " 'v84',\n",
       " 'v106',\n",
       " 'v51',\n",
       " 'v15',\n",
       " 'v13',\n",
       " 'v83',\n",
       " 'v109',\n",
       " 'v44',\n",
       " 'v63',\n",
       " 'v105',\n",
       " 'v104',\n",
       " 'v4',\n",
       " 'v60',\n",
       " 'v116',\n",
       " 'v96',\n",
       " 'v41',\n",
       " 'v94',\n",
       " 'v67',\n",
       " 'v128',\n",
       " 'v53',\n",
       " 'v64',\n",
       " 'v17',\n",
       " 'v100',\n",
       " 'v62',\n",
       " 'v76',\n",
       " 'v95',\n",
       " 'v48']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the list of ordered features\n",
    "features = list(features.index)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test one feature xgb ROC AUC=0.681754\n"
     ]
    }
   ],
   "source": [
    "# next, we need to build a machine learning\n",
    "# algorithm using only the most important feature\n",
    "\n",
    "# set the seed for reproducibility\n",
    "seed_val = 1000000000\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# build initial model using all the features\n",
    "model_one_feature = xgb.XGBClassifier(\n",
    "    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "# train using only the most important feature\n",
    "model_one_feature.fit(X_train[features[0]].to_frame(), y_train)\n",
    "\n",
    "# calculate the roc-auc in the test set\n",
    "y_pred_test = model_one_feature.predict_proba(X_test[features[0]].to_frame())[:, 1]\n",
    "auc_score_first = roc_auc_score(y_test, y_pred_test)\n",
    "print('Test one feature xgb ROC AUC=%f' % (auc_score_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing recursive feature addition\n",
      "\n",
      "testing feature:  v10  which is feature  1  out of  112\n",
      "New Test ROC AUC=0.7007286667701044\n",
      "All features Test ROC AUC=0.681754474366548\n",
      "Increase in ROC AUC=0.018974192403556356\n",
      "keep:  v10\n",
      "\n",
      "testing feature:  v21  which is feature  2  out of  112\n",
      "New Test ROC AUC=0.698898868421512\n",
      "All features Test ROC AUC=0.7007286667701044\n",
      "Increase in ROC AUC=-0.0018297983485923153\n",
      "remove:  v21\n",
      "\n",
      "testing feature:  v114  which is feature  3  out of  112\n",
      "New Test ROC AUC=0.7066980932102036\n",
      "All features Test ROC AUC=0.7007286667701044\n",
      "Increase in ROC AUC=0.005969426440099235\n",
      "keep:  v114\n",
      "\n",
      "testing feature:  v12  which is feature  4  out of  112\n",
      "New Test ROC AUC=0.7073187692534103\n",
      "All features Test ROC AUC=0.7066980932102036\n",
      "Increase in ROC AUC=0.0006206760432067027\n",
      "remove:  v12\n",
      "\n",
      "testing feature:  v34  which is feature  5  out of  112\n",
      "New Test ROC AUC=0.7070767006646881\n",
      "All features Test ROC AUC=0.7066980932102036\n",
      "Increase in ROC AUC=0.00037860745448448085\n",
      "remove:  v34\n",
      "\n",
      "testing feature:  v14  which is feature  6  out of  112\n",
      "New Test ROC AUC=0.7084757493461078\n",
      "All features Test ROC AUC=0.7066980932102036\n",
      "Increase in ROC AUC=0.0017776561359041931\n",
      "keep:  v14\n",
      "\n",
      "testing feature:  v40  which is feature  7  out of  112\n",
      "New Test ROC AUC=0.7080178004069582\n",
      "All features Test ROC AUC=0.7084757493461078\n",
      "Increase in ROC AUC=-0.00045794893914963275\n",
      "remove:  v40\n",
      "\n",
      "testing feature:  v23  which is feature  8  out of  112\n",
      "New Test ROC AUC=0.7088500907316422\n",
      "All features Test ROC AUC=0.7084757493461078\n",
      "Increase in ROC AUC=0.00037434138553438245\n",
      "remove:  v23\n",
      "\n",
      "testing feature:  v129  which is feature  9  out of  112\n",
      "New Test ROC AUC=0.7115412404584314\n",
      "All features Test ROC AUC=0.7084757493461078\n",
      "Increase in ROC AUC=0.0030654911123235706\n",
      "keep:  v129\n",
      "\n",
      "testing feature:  v99  which is feature  10  out of  112\n",
      "New Test ROC AUC=0.711928380050816\n",
      "All features Test ROC AUC=0.7115412404584314\n",
      "Increase in ROC AUC=0.00038713959238467766\n",
      "remove:  v99\n",
      "\n",
      "testing feature:  v6  which is feature  11  out of  112\n",
      "New Test ROC AUC=0.7110010772193989\n",
      "All features Test ROC AUC=0.7115412404584314\n",
      "Increase in ROC AUC=-0.0005401632390324984\n",
      "remove:  v6\n",
      "\n",
      "testing feature:  v69  which is feature  12  out of  112\n",
      "New Test ROC AUC=0.7123081464951309\n",
      "All features Test ROC AUC=0.7115412404584314\n",
      "Increase in ROC AUC=0.0007669060366994884\n",
      "remove:  v69\n",
      "\n",
      "testing feature:  v102  which is feature  13  out of  112\n",
      "New Test ROC AUC=0.7120518371271098\n",
      "All features Test ROC AUC=0.7115412404584314\n",
      "Increase in ROC AUC=0.0005105966686784758\n",
      "remove:  v102\n",
      "\n",
      "testing feature:  v87  which is feature  14  out of  112\n",
      "New Test ROC AUC=0.7110819722436238\n",
      "All features Test ROC AUC=0.7115412404584314\n",
      "Increase in ROC AUC=-0.0004592682148075733\n",
      "remove:  v87\n",
      "\n",
      "testing feature:  v39  which is feature  15  out of  112\n",
      "New Test ROC AUC=0.7108788531110098\n",
      "All features Test ROC AUC=0.7115412404584314\n",
      "Increase in ROC AUC=-0.0006623873474215225\n",
      "remove:  v39\n",
      "\n",
      "testing feature:  v16  which is feature  16  out of  112\n",
      "New Test ROC AUC=0.7109822867885319\n",
      "All features Test ROC AUC=0.7115412404584314\n",
      "Increase in ROC AUC=-0.0005589536698994424\n",
      "remove:  v16\n",
      "\n",
      "testing feature:  v42  which is feature  17  out of  112\n",
      "New Test ROC AUC=0.7108141469553733\n",
      "All features Test ROC AUC=0.7115412404584314\n",
      "Increase in ROC AUC=-0.0007270935030581072\n",
      "remove:  v42\n",
      "\n",
      "testing feature:  v38  which is feature  18  out of  112\n",
      "New Test ROC AUC=0.7149457977445366\n",
      "All features Test ROC AUC=0.7115412404584314\n",
      "Increase in ROC AUC=0.0034045572861052253\n",
      "keep:  v38\n",
      "\n",
      "testing feature:  v57  which is feature  19  out of  112\n",
      "New Test ROC AUC=0.714276185205194\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=-0.0006696125393426122\n",
      "remove:  v57\n",
      "\n",
      "testing feature:  v18  which is feature  20  out of  112\n",
      "New Test ROC AUC=0.7155884329461255\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=0.0006426352015889147\n",
      "remove:  v18\n",
      "\n",
      "testing feature:  v127  which is feature  21  out of  112\n",
      "New Test ROC AUC=0.714330978298877\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=-0.0006148194456595535\n",
      "remove:  v127\n",
      "\n",
      "testing feature:  v123  which is feature  22  out of  112\n",
      "New Test ROC AUC=0.7148353238202789\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=-0.00011047392425767022\n",
      "remove:  v123\n",
      "\n",
      "testing feature:  v85  which is feature  23  out of  112\n",
      "New Test ROC AUC=0.7145186853326828\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=-0.00042711241185378057\n",
      "remove:  v85\n",
      "\n",
      "testing feature:  v131  which is feature  24  out of  112\n",
      "New Test ROC AUC=0.7140444242281547\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=-0.0009013735163818648\n",
      "remove:  v131\n",
      "\n",
      "testing feature:  v82  which is feature  25  out of  112\n",
      "New Test ROC AUC=0.7146086180116489\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=-0.00033717973288771574\n",
      "remove:  v82\n",
      "\n",
      "testing feature:  v73  which is feature  26  out of  112\n",
      "New Test ROC AUC=0.7143114234279092\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=-0.0006343743166273841\n",
      "remove:  v73\n",
      "\n",
      "testing feature:  v72  which is feature  27  out of  112\n",
      "New Test ROC AUC=0.7145700137865539\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=-0.00037578395798265607\n",
      "remove:  v72\n",
      "\n",
      "testing feature:  v124  which is feature  28  out of  112\n",
      "New Test ROC AUC=0.7157643158177256\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=0.0008185180731890007\n",
      "remove:  v124\n",
      "\n",
      "testing feature:  v19  which is feature  29  out of  112\n",
      "New Test ROC AUC=0.7136996617426532\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=-0.0012461360018833911\n",
      "remove:  v19\n",
      "\n",
      "testing feature:  v78  which is feature  30  out of  112\n",
      "New Test ROC AUC=0.7163906018648984\n",
      "All features Test ROC AUC=0.7149457977445366\n",
      "Increase in ROC AUC=0.0014448041203618534\n",
      "keep:  v78\n",
      "\n",
      "testing feature:  v92  which is feature  31  out of  112\n",
      "New Test ROC AUC=0.714511583437552\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0018790184273465016\n",
      "remove:  v92\n",
      "\n",
      "testing feature:  v55  which is feature  32  out of  112\n",
      "New Test ROC AUC=0.7161854360055627\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.00020516585933572085\n",
      "remove:  v55\n",
      "\n",
      "testing feature:  v35  which is feature  33  out of  112\n",
      "New Test ROC AUC=0.7151407299702637\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0012498718946347687\n",
      "remove:  v35\n",
      "\n",
      "testing feature:  v122  which is feature  34  out of  112\n",
      "New Test ROC AUC=0.7157990115345627\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0005915903303357339\n",
      "remove:  v122\n",
      "\n",
      "testing feature:  v80  which is feature  35  out of  112\n",
      "New Test ROC AUC=0.7155579169904851\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0008326848744133475\n",
      "remove:  v80\n",
      "\n",
      "testing feature:  v45  which is feature  36  out of  112\n",
      "New Test ROC AUC=0.7158824218133132\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0005081800515852608\n",
      "remove:  v45\n",
      "\n",
      "testing feature:  v86  which is feature  37  out of  112\n",
      "New Test ROC AUC=0.7154310569227745\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0009595449421239133\n",
      "remove:  v86\n",
      "\n",
      "testing feature:  v130  which is feature  38  out of  112\n",
      "New Test ROC AUC=0.7140151658997771\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.002375435965121353\n",
      "remove:  v130\n",
      "\n",
      "testing feature:  v28  which is feature  39  out of  112\n",
      "New Test ROC AUC=0.7162365671845691\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0001540346803293735\n",
      "remove:  v28\n",
      "\n",
      "testing feature:  v32  which is feature  40  out of  112\n",
      "New Test ROC AUC=0.7150318465746031\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.001358755290295388\n",
      "remove:  v32\n",
      "\n",
      "testing feature:  v126  which is feature  41  out of  112\n",
      "New Test ROC AUC=0.7159124815708287\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.00047812029406979484\n",
      "remove:  v126\n",
      "\n",
      "testing feature:  v36  which is feature  42  out of  112\n",
      "New Test ROC AUC=0.7162804731716541\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.00011012869324433794\n",
      "remove:  v36\n",
      "\n",
      "testing feature:  v97  which is feature  43  out of  112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Test ROC AUC=0.7140841504540429\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0023064514108555034\n",
      "remove:  v97\n",
      "\n",
      "testing feature:  v1  which is feature  44  out of  112\n",
      "New Test ROC AUC=0.7158929020405027\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0004976998243957365\n",
      "remove:  v1\n",
      "\n",
      "testing feature:  v120  which is feature  45  out of  112\n",
      "New Test ROC AUC=0.7154213164763277\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0009692853885707731\n",
      "remove:  v120\n",
      "\n",
      "testing feature:  v5  which is feature  46  out of  112\n",
      "New Test ROC AUC=0.7156575531268609\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0007330487380375894\n",
      "remove:  v5\n",
      "\n",
      "testing feature:  v59  which is feature  47  out of  112\n",
      "New Test ROC AUC=0.7159067112810349\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.00048389058386355543\n",
      "remove:  v59\n",
      "\n",
      "testing feature:  v27  which is feature  48  out of  112\n",
      "New Test ROC AUC=0.7145256516013442\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0018649502635542659\n",
      "remove:  v27\n",
      "\n",
      "testing feature:  v9  which is feature  49  out of  112\n",
      "New Test ROC AUC=0.7156645933735964\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0007260084913019993\n",
      "remove:  v9\n",
      "\n",
      "testing feature:  v68  which is feature  50  out of  112\n",
      "New Test ROC AUC=0.7155276352987466\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0008629665661518127\n",
      "remove:  v68\n",
      "\n",
      "testing feature:  v103  which is feature  51  out of  112\n",
      "New Test ROC AUC=0.7151706294419519\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0012199724229465803\n",
      "remove:  v103\n",
      "\n",
      "testing feature:  v119  which is feature  52  out of  112\n",
      "New Test ROC AUC=0.7161536994116968\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.00023690245320162617\n",
      "remove:  v119\n",
      "\n",
      "testing feature:  v11  which is feature  53  out of  112\n",
      "New Test ROC AUC=0.715223055237258\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0011675466276404034\n",
      "remove:  v11\n",
      "\n",
      "testing feature:  v90  which is feature  54  out of  112\n",
      "New Test ROC AUC=0.7149211137270854\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.001469488137813002\n",
      "remove:  v90\n",
      "\n",
      "testing feature:  v98  which is feature  55  out of  112\n",
      "New Test ROC AUC=0.7150642613008167\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0013263405640817627\n",
      "remove:  v98\n",
      "\n",
      "testing feature:  v88  which is feature  56  out of  112\n",
      "New Test ROC AUC=0.7156686375083238\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0007219643565746781\n",
      "remove:  v88\n",
      "\n",
      "testing feature:  v37  which is feature  57  out of  112\n",
      "New Test ROC AUC=0.7165169687454471\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=0.0001263668805486784\n",
      "remove:  v37\n",
      "\n",
      "testing feature:  v2  which is feature  58  out of  112\n",
      "New Test ROC AUC=0.7155295217396408\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0008610801252576517\n",
      "remove:  v2\n",
      "\n",
      "testing feature:  v81  which is feature  59  out of  112\n",
      "New Test ROC AUC=0.715782958292444\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0006076435724544638\n",
      "remove:  v81\n",
      "\n",
      "testing feature:  v54  which is feature  60  out of  112\n",
      "New Test ROC AUC=0.7153694455165784\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.001021156348320007\n",
      "remove:  v54\n",
      "\n",
      "testing feature:  v118  which is feature  61  out of  112\n",
      "New Test ROC AUC=0.7152049922574548\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0011856096074436273\n",
      "remove:  v118\n",
      "\n",
      "testing feature:  v70  which is feature  62  out of  112\n",
      "New Test ROC AUC=0.7147178836273601\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0016727182375383398\n",
      "remove:  v70\n",
      "\n",
      "testing feature:  v61  which is feature  63  out of  112\n",
      "New Test ROC AUC=0.7157452541339193\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0006453477309791289\n",
      "remove:  v61\n",
      "\n",
      "testing feature:  v101  which is feature  64  out of  112\n",
      "New Test ROC AUC=0.716980798941502\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=0.0005901970766035713\n",
      "remove:  v101\n",
      "\n",
      "testing feature:  v108  which is feature  65  out of  112\n",
      "New Test ROC AUC=0.7132991074594657\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.003091494405432771\n",
      "remove:  v108\n",
      "\n",
      "testing feature:  v117  which is feature  66  out of  112\n",
      "New Test ROC AUC=0.716257959177715\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.00013264268718349292\n",
      "remove:  v117\n",
      "\n",
      "testing feature:  v26  which is feature  67  out of  112\n",
      "New Test ROC AUC=0.7150348920053275\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0013557098595708972\n",
      "remove:  v26\n",
      "\n",
      "testing feature:  v49  which is feature  68  out of  112\n",
      "New Test ROC AUC=0.7150419815707794\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.001348620294119085\n",
      "remove:  v49\n",
      "\n",
      "testing feature:  v89  which is feature  69  out of  112\n",
      "New Test ROC AUC=0.7157525163148779\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0006380855500205396\n",
      "remove:  v89\n",
      "\n",
      "testing feature:  v111  which is feature  70  out of  112\n",
      "New Test ROC AUC=0.7153862385394401\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0010043633254583906\n",
      "remove:  v111\n",
      "\n",
      "testing feature:  v58  which is feature  71  out of  112\n",
      "New Test ROC AUC=0.7145029526622193\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0018876492026791425\n",
      "remove:  v58\n",
      "\n",
      "testing feature:  v77  which is feature  72  out of  112\n",
      "New Test ROC AUC=0.7151284372802543\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.001262164584644121\n",
      "remove:  v77\n",
      "\n",
      "testing feature:  v33  which is feature  73  out of  112\n",
      "New Test ROC AUC=0.7159633291672169\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0004272726976815022\n",
      "remove:  v33\n",
      "\n",
      "testing feature:  v43  which is feature  74  out of  112\n",
      "New Test ROC AUC=0.715203204453993\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0011873974109054553\n",
      "remove:  v43\n",
      "\n",
      "testing feature:  v20  which is feature  75  out of  112\n",
      "New Test ROC AUC=0.715243682790303\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0011469190745954094\n",
      "remove:  v20\n",
      "\n",
      "testing feature:  v93  which is feature  76  out of  112\n",
      "New Test ROC AUC=0.716555240069208\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=0.000164638204309564\n",
      "remove:  v93\n",
      "\n",
      "testing feature:  v25  which is feature  77  out of  112\n",
      "New Test ROC AUC=0.7159045289278437\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.00048607293705471566\n",
      "remove:  v25\n",
      "\n",
      "testing feature:  v65  which is feature  78  out of  112\n",
      "New Test ROC AUC=0.7150731756587674\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.001317426206131067\n",
      "remove:  v65\n",
      "\n",
      "testing feature:  v46  which is feature  79  out of  112\n",
      "New Test ROC AUC=0.7154296636690423\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0009609381958561869\n",
      "remove:  v46\n",
      "\n",
      "testing feature:  v29  which is feature  80  out of  112\n",
      "New Test ROC AUC=0.7163339593193584\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-5.664254554005321e-05\n",
      "remove:  v29\n",
      "\n",
      "testing feature:  v8  which is feature  81  out of  112\n",
      "New Test ROC AUC=0.7142924850408936\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0020981168240048476\n",
      "remove:  v8\n",
      "\n",
      "testing feature:  v7  which is feature  82  out of  112\n",
      "New Test ROC AUC=0.7147667954641379\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=-0.0016238064007605413\n",
      "remove:  v7\n",
      "\n",
      "testing feature:  v115  which is feature  83  out of  112\n",
      "New Test ROC AUC=0.7165622433269065\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=0.0001716414620080986\n",
      "remove:  v115\n",
      "\n",
      "testing feature:  v121  which is feature  84  out of  112\n",
      "New Test ROC AUC=0.7174189587457817\n",
      "All features Test ROC AUC=0.7163906018648984\n",
      "Increase in ROC AUC=0.0010283568808832078\n",
      "keep:  v121\n",
      "\n",
      "testing feature:  v84  which is feature  85  out of  112\n",
      "New Test ROC AUC=0.7163774584270348\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0010415003187468352\n",
      "remove:  v84\n",
      "\n",
      "testing feature:  v106  which is feature  86  out of  112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Test ROC AUC=0.7157865092400094\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0016324495057722377\n",
      "remove:  v106\n",
      "\n",
      "testing feature:  v51  which is feature  87  out of  112\n",
      "New Test ROC AUC=0.7168127824051337\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0006061763406479681\n",
      "remove:  v51\n",
      "\n",
      "testing feature:  v15  which is feature  88  out of  112\n",
      "New Test ROC AUC=0.7160561839801172\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0013627747656644873\n",
      "remove:  v15\n",
      "\n",
      "testing feature:  v13  which is feature  89  out of  112\n",
      "New Test ROC AUC=0.7169035535022749\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0005154052435067946\n",
      "remove:  v13\n",
      "\n",
      "testing feature:  v83  which is feature  90  out of  112\n",
      "New Test ROC AUC=0.7159513817082208\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.001467577037560841\n",
      "remove:  v83\n",
      "\n",
      "testing feature:  v109  which is feature  91  out of  112\n",
      "New Test ROC AUC=0.7177597387449511\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=0.00034077999916948265\n",
      "remove:  v109\n",
      "\n",
      "testing feature:  v44  which is feature  92  out of  112\n",
      "New Test ROC AUC=0.7166807068831864\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0007382518625952406\n",
      "remove:  v44\n",
      "\n",
      "testing feature:  v63  which is feature  93  out of  112\n",
      "New Test ROC AUC=0.7157909479244662\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0016280108213154731\n",
      "remove:  v63\n",
      "\n",
      "testing feature:  v105  which is feature  94  out of  112\n",
      "New Test ROC AUC=0.7144077798696585\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0030111788761231217\n",
      "remove:  v105\n",
      "\n",
      "testing feature:  v104  which is feature  95  out of  112\n",
      "New Test ROC AUC=0.7170386374659097\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0003803212798719757\n",
      "remove:  v104\n",
      "\n",
      "testing feature:  v4  which is feature  96  out of  112\n",
      "New Test ROC AUC=0.716018356524802\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0014006022209797075\n",
      "remove:  v4\n",
      "\n",
      "testing feature:  v60  which is feature  97  out of  112\n",
      "New Test ROC AUC=0.7154320432970983\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0019869154486833462\n",
      "remove:  v60\n",
      "\n",
      "testing feature:  v116  which is feature  98  out of  112\n",
      "New Test ROC AUC=0.716175695559116\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0012432631866656774\n",
      "remove:  v116\n",
      "\n",
      "testing feature:  v96  which is feature  99  out of  112\n",
      "New Test ROC AUC=0.7162092939345179\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.001209664811263722\n",
      "remove:  v96\n",
      "\n",
      "testing feature:  v41  which is feature  100  out of  112\n",
      "New Test ROC AUC=0.7157881120982855\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0016308466474961314\n",
      "remove:  v41\n",
      "\n",
      "testing feature:  v94  which is feature  101  out of  112\n",
      "New Test ROC AUC=0.7163700729492859\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0010488857964957576\n",
      "remove:  v94\n",
      "\n",
      "testing feature:  v67  which is feature  102  out of  112\n",
      "New Test ROC AUC=0.7150697110189552\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.002349247726826431\n",
      "remove:  v67\n",
      "\n",
      "testing feature:  v128  which is feature  103  out of  112\n",
      "New Test ROC AUC=0.7165674587811433\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0008514999646384025\n",
      "remove:  v128\n",
      "\n",
      "testing feature:  v53  which is feature  104  out of  112\n",
      "New Test ROC AUC=0.715939767150559\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0014791915952226953\n",
      "remove:  v53\n",
      "\n",
      "testing feature:  v64  which is feature  105  out of  112\n",
      "New Test ROC AUC=0.7153642177326628\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.002054741013118866\n",
      "remove:  v64\n",
      "\n",
      "testing feature:  v17  which is feature  106  out of  112\n",
      "New Test ROC AUC=0.716004880185604\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0014140785601776118\n",
      "remove:  v17\n",
      "\n",
      "testing feature:  v100  which is feature  107  out of  112\n",
      "New Test ROC AUC=0.7161454261970565\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.001273532548725198\n",
      "remove:  v100\n",
      "\n",
      "testing feature:  v62  which is feature  108  out of  112\n",
      "New Test ROC AUC=0.7171562132852982\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.00026274546048343783\n",
      "remove:  v62\n",
      "\n",
      "testing feature:  v76  which is feature  109  out of  112\n",
      "New Test ROC AUC=0.7155479669394944\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0018709918062872477\n",
      "remove:  v76\n",
      "\n",
      "testing feature:  v95  which is feature  110  out of  112\n",
      "New Test ROC AUC=0.7160981911966289\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0013207675491527793\n",
      "remove:  v95\n",
      "\n",
      "testing feature:  v48  which is feature  111  out of  112\n",
      "New Test ROC AUC=0.7161019024300219\n",
      "All features Test ROC AUC=0.7174189587457817\n",
      "Increase in ROC AUC=-0.0013170563157597348\n",
      "remove:  v48\n",
      "DONE!!\n",
      "total features to keep:  8\n"
     ]
    }
   ],
   "source": [
    "# the final step consists in adding one at a time\n",
    "# all the features, from the most to the least\n",
    "# important, and build an xgboost at each round.\n",
    "\n",
    "# once we build the model, we calculate the new roc-auc\n",
    "# if the new roc-auc is bigger than the original one\n",
    "# (with one feature), then that feature that was added\n",
    "# was important, and we should keep it.\n",
    "# otherwise, we should remove the feature\n",
    "\n",
    "# recursive feature addition:\n",
    "\n",
    "# first we arbitrarily set the increase in roc-auc\n",
    "# if the increase is above this threshold,\n",
    "# the feature will be kept\n",
    "tol = 0.001\n",
    "\n",
    "print('doing recursive feature addition')\n",
    "\n",
    "# we initialise a list where we will collect the\n",
    "# features we should keep\n",
    "features_to_keep = [features[0]]\n",
    "\n",
    "# set a counter to know how far ahead the loop is going\n",
    "count = 1\n",
    "\n",
    "# now we loop over all the features, in order of importance:\n",
    "# remember that features is the list of ordered features\n",
    "# by importance\n",
    "for feature in features[1:]:\n",
    "    print()\n",
    "    print('testing feature: ', feature, ' which is feature ', count,\n",
    "          ' out of ', len(features))\n",
    "    count = count + 1\n",
    "\n",
    "    # initialise model\n",
    "    model_int = xgb.XGBClassifier(\n",
    "        nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "    # fit model with the selected features\n",
    "    # and the feature to be evaluated\n",
    "    model_int.fit(\n",
    "        X_train[features_to_keep + [feature] ], y_train)\n",
    "\n",
    "    # make a prediction over the test set\n",
    "    y_pred_test = model_int.predict_proba(\n",
    "        X_test[features_to_keep + [feature] ])[:, 1]\n",
    "\n",
    "    # calculate the new roc-auc\n",
    "    auc_score_int = roc_auc_score(y_test, y_pred_test)\n",
    "    print('New Test ROC AUC={}'.format((auc_score_int)))\n",
    "\n",
    "    # print the original roc-auc with one feature\n",
    "    print('All features Test ROC AUC={}'.format((auc_score_first)))\n",
    "\n",
    "    # determine the increase in the roc-auc\n",
    "    diff_auc = auc_score_int - auc_score_first\n",
    "\n",
    "    # compare the increase in roc-auc with the tolerance\n",
    "    # we set previously\n",
    "    if diff_auc >= tol:\n",
    "        print('Increase in ROC AUC={}'.format(diff_auc))\n",
    "        print('keep: ', feature)\n",
    "        print\n",
    "        # if the increase in the roc is bigger than the threshold\n",
    "        # we keep the feature and re-adjust the roc-auc to the new value\n",
    "        # considering the added feature\n",
    "        auc_score_first = auc_score_int\n",
    "        \n",
    "        # and we append the feature to keep to the list\n",
    "        features_to_keep.append(feature)\n",
    "    else:\n",
    "        # we ignore the feature\n",
    "        print('Increase in ROC AUC={}'.format(diff_auc))\n",
    "        print('remove: ', feature)\n",
    "        print\n",
    "\n",
    "\n",
    "# now the loop is finished, we evaluated all the features\n",
    "print('DONE!!')\n",
    "print('total features to keep: ', len(features_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test selected features ROC AUC=0.717419\n"
     ]
    }
   ],
   "source": [
    "# capture the 8 selected features\n",
    "seed_val = 1000000000\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# build initial model\n",
    "final_xgb = xgb.XGBClassifier(\n",
    "    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "# fit the model with the selected features\n",
    "final_xgb.fit(X_train[features_to_keep], y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred_test = final_xgb.predict_proba(X_test[features_to_keep])[:, 1]\n",
    "\n",
    "# calculate roc-auc\n",
    "auc_score_final = roc_auc_score(y_test, y_pred_test)\n",
    "print('Test selected features ROC AUC=%f' % (auc_score_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a threshold / tolerance of 0.001 we selected 8 features. The model built with 8 features is far more predictive than the one built with 1 feature. In addition, the model built with 8 features is more predictive than the one built with all the features (0.717 vs 0.713). \n",
    "And if you remember from the previous lecture where we selected 56 features by recursive feature elimination, the roc-auc was 0.715, which indicates that many of those features are still redundant, as a model built with 8 features seems to perform better.\n",
    "\n",
    "Here we got a good uplift with just one try. However, in practice you may need to run a few runs of these method and find the right threshold, depending on how many features you are willing to include in your model and how accurate you would like it to be.\n",
    "\n",
    "Why don't you give it a go?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('houseprice.csv', nrows=50000)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 38)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 36), (438, 36))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['Id','SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test all features xgb R2 = 0.818551\n"
     ]
    }
   ],
   "source": [
    "# the first step of this procedure consists in building\n",
    "# a machine learning algorithm using all the available features\n",
    "# and then determine the importance of the features according\n",
    "# to the algorithm\n",
    "\n",
    "# set the seed for reproducibility\n",
    "seed_val = 1000000000\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# build initial model using all the features\n",
    "model_all_features = xgb.XGBRegressor(\n",
    "    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "model_all_features.fit(X_train, y_train)\n",
    "\n",
    "# calculate the roc-auc in the test set\n",
    "y_pred_test = model_all_features.predict(X_test)\n",
    "r2_score_all = r2_score(y_test, y_pred_test)\n",
    "print('Test all features xgb R2 = %f' % (r2_score_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x4fb2f306d8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIUAAAGiCAYAAAB53XaEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XmcHVWZ//FPQlgEgmxxwY0B8RFccAEFRBgYQUVR/In7\nSowIisowMAYHnWFExYVBUBCCxAEVF0QQXMBRRGVzwQ0VHkEUFFBAwiayBPr3x6mbVNrupBO6zk1S\nn/frlVdu9+3bT92+3beqvnXOc6aMjIwgSZIkSZKkfpk67A2QJEmSJElSfYZCkiRJkiRJPWQoJEmS\nJEmS1EOGQpIkSZIkST1kKCRJkiRJktRD04a9AQM33nj7Mi+Dtt56azJv3p2TuTnWtra1rW1ta1vb\n2ta2trWtbW1rW9vaK3ztGTOmTxnvvpVipNC0aatY29rWtra1rW1ta1vb2ta2trWtbW1rW3sprBSh\nkCRJkiRJkpaOoZAkSZIkSVIPGQpJkiRJkiT10BIbTUfEVOBYYEvgbmBWZl456mvWBP4PeFNmXj6R\nx0iSJEmSJGl4JjJSaA9gjczcFpgNHNG+MyK2Ar4PbDrRx0iSJEmSJGm4JhIKbQ+cDZCZFwNbjbp/\ndeAlwOVL8RhJkiRJkiQN0ZSRkZHFfkFEfAo4LTO/2Xx8DbBJZs4f9XXnAfs008cm9Ji2+fPvGxnm\nEm+SJEmSJEkroSnj3bHEnkLAbcD01sdTFxfuLOtj5s27cwKbMrYZM6Zz4423L/PjHwhrW9va1ra2\nta1tbWtb29rWtra1rW3t5bX2jBnTx71vItPHLgB2A4iIbYBLO3qMJEmSJEmSKpnISKHTgV0i4kLK\nkKO9IuLVwNqZOWeij5mUrZUkSZIkSdKkWGIolJn3A/uM+vTlY3zdPy/hMZIkSZIkSVpOTGT6mCRJ\nkiRJklYyhkKSJEmSJEk9ZCgkSZIkSZLUQxNpNL1cmHn4ucv82Lmzd57ELZEkSZIkSVrxOVJIkiRJ\nkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBIkiRJ\nkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBIkiRJ\nkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBIkiRJ\nkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBIkiRJ\nkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBIkiRJ\nkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBIkiRJ\nkiSphwyFJEmSJEmSeshQSJIkSZIkqYemDXsDVgQzDz93mR87d/bOk7glkiRJkiRJk8ORQpIkSZIk\nST1kKCRJkiRJktRDhkKSJEmSJEk9ZCgkSZIkSZLUQ4ZCkiRJkiRJPWQoJEmSJEmS1EOGQpIkSZIk\nST1kKCRJkiRJktRDhkKSJEmSJEk9ZCgkSZIkSZLUQ4ZCkiRJkiRJPWQoJEmSJEmS1EPTlvQFETEV\nOBbYErgbmJWZV7bu3x14LzAfmJuZJ0TEqsBJwMbAfcCbM/Pyyd98SZIkSZIkLYuJjBTaA1gjM7cF\nZgNHDO5owp8jgV2BHYG9I+KhwG7AtMzcDvhv4P2TveGSJEmSJEladkscKQRsD5wNkJkXR8RWrfs2\nB67MzHkAEXE+sAPwK2BaM8poHeDeJRVZb701mTZtlaXc/ImZMWN6J993eai9Mj83a1vb2ta2trWt\nbW1rW9va1ra2ta3dXe2JhELrALe2Pr4vIqZl5vwx7rsdeDBwB2Xq2OXAhsALl1Rk3rw7J7jJS+/G\nG2/v7HsPs/aMGdOH9tysbW1rW9va1ra2ta1tbWtb29rWtvbyX3txgdJEpo/dBrS/w9QmEBrrvunA\nLcC/Audk5uMovYhOiog1lmajJUmSJEmS1J2JhEIXUHoEERHbAJe27rsM2Cwi1o+I1ShTxy4C5rFw\nBNHNwKpAN3PDJEmSJEmStNQmMn3sdGCXiLgQmALsFRGvBtbOzDkRcQBwDiVgmpuZ10bEkcDciPgB\nsBrw7sz8W0fPQZIkSZIkSUtpiaFQZt4P7DPq05e37j8LOGvUY+4AXj4ZGyhJkiRJkqTJN5HpY5Ik\nSZIkSVrJGApJkiRJkiT1kKGQJEmSJElSDxkKSZIkSZIk9ZChkCRJkiRJUg8ZCkmSJEmSJPWQoZAk\nSZIkSVIPGQpJkiRJkiT1kKGQJEmSJElSDxkKSZIkSZIk9ZChkCRJkiRJUg8ZCkmSJEmSJPWQoZAk\nSZIkSVIPGQpJkiRJkiT1kKGQJEmSJElSDxkKSZIkSZIk9ZChkCRJkiRJUg8ZCkmSJEmSJPWQoZAk\nSZIkSVIPGQpJkiRJkiT1kKGQJEmSJElSDxkKSZIkSZIk9ZChkCRJkiRJUg8ZCkmSJEmSJPWQoZAk\nSZIkSVIPGQpJkiRJkiT1kKGQJEmSJElSDxkKSZIkSZIk9ZChkCRJkiRJUg8ZCkmSJEmSJPWQoZAk\nSZIkSVIPGQpJkiRJkiT1kKGQJEmSJElSDxkKSZIkSZIk9ZChkCRJkiRJUg8ZCkmSJEmSJPWQoZAk\nSZIkSVIPGQpJkiRJkiT1kKGQJEmSJElSDxkKSZIkSZIk9ZChkCRJkiRJUg9NG/YGaPFmHn7uMj92\n7uydJ3FLJEmSJEnSysSRQpIkSZIkST1kKCRJkiRJktRDhkKSJEmSJEk9ZE8hjct+RpIkSZIkrbwc\nKSRJkiRJktRDhkKSJEmSJEk9ZCgkSZIkSZLUQ4ZCkiRJkiRJPWQoJEmSJEmS1EOGQpIkSZIkST1k\nKCRJkiRJktRDhkKSJEmSJEk9ZCgkSZIkSZLUQ9OW9AURMRU4FtgSuBuYlZlXtu7fHXgvMB+Ym5kn\nNJ8/GHgRsBpwbGaeOPmbL0mSJEmSpGWxxFAI2ANYIzO3jYhtgCOAFwNExKrAkcDWwN+ACyLiTGBz\nYDvgWcCawIEdbLskSZIkSZKW0USmj20PnA2QmRcDW7Xu2xy4MjPnZeY9wPnADsBzgUuB04GzgK9N\n5kZLkiRJkiTpgZnISKF1gFtbH98XEdMyc/4Y990OPBjYEHgM8ELgn4AzI+LxmTkyXpH11luTadNW\nWdrtn5AZM6Z38n2tPbzaK/Nzs7a1rW1ta1vb2ta2trWtbW1rW7tG7YmEQrcB7epTm0BorPumA7cA\nfwUub0YPZUTcBcwAbhivyLx5dy7Ndi+VG2+8vbPvbe36tWfMmD6052Zta1vb2ta2trWtbW1rW9va\n1rb2ilR7cYHSRKaPXQDsBtD0FLq0dd9lwGYRsX5ErEaZOnYRZRrZ8yJiSkRsBKxFCYokSZIkSZK0\nHJjISKHTgV0i4kJgCrBXRLwaWDsz50TEAcA5lIBpbmZeC1wbETsAP2o+/7bMvK+bpyBJkiRJkqSl\ntcRQKDPvB/YZ9enLW/efRWkmPfpx//6At06SJEmSJEmdmMj0MUmSJEmSJK1kDIUkSZIkSZJ6yFBI\nkiRJkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBI\nkiRJkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBI\nkiRJkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBI\nkiRJkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHDIUkSZIkSZJ6yFBI\nkiRJkiSph6YNewOkscw8/Nxlfuzc2TtP4pZIkiRJkrRycqSQJEmSJElSDxkKSZIkSZIk9ZChkCRJ\nkiRJUg8ZCkmSJEmSJPWQoZAkSZIkSVIPGQpJkiRJkiT1kKGQJEmSJElSDxkKSZIkSZIk9ZChkCRJ\nkiRJUg8ZCkmSJEmSJPXQtGFvgLS8mXn4ucv82Lmzd57ELZEkSZIkqTuGQtJyxEBKkiRJklSL08ck\nSZIkSZJ6yFBIkiRJkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmHXJJe\nEgAzDz93mR87d/bOk7glkiRJkqQaHCkkSZIkSZLUQ4ZCkiRJkiRJPWQoJEmSJEmS1EP2FJI0dPYz\nkiRJkqT6HCkkSZIkSZLUQ4ZCkiRJkiRJPWQoJEmSJEmS1EOGQpIkSZIkST1ko2lJvWaTa0mSJEl9\ntcRQKCKmAscCWwJ3A7My88rW/bsD7wXmA3Mz84TWfQ8BLgF2yczLJ3nbJUmSJEmStIwmMn1sD2CN\nzNwWmA0cMbgjIlYFjgR2BXYE9o6Ih7buOx74+2RvtCRJkiRJkh6YiYRC2wNnA2TmxcBWrfs2B67M\nzHmZeQ9wPrBDc99HgeOA6yZvcyVJkiRJkjQZJtJTaB3g1tbH90XEtMycP8Z9twMPjog3Ajdm5jkR\ncfBENmS99dZk2rRVJrjZS2fGjOmdfF9rW9va1l6Rv7+1rW1ta1vb2ta2trWtbe1+155IKHQb0K4+\ntQmExrpvOnAL8A5gJCKeAzwFODkiXpSZfx6vyLx5dy7Vhi+NG2+8vbPvbW1rW9vaXZgxY/rQnpu1\nrW1ta1vb2ta2trWtbe2Vp/biAqWJhEIXALsDX4qIbYBLW/ddBmwWEesDd1Cmjn00M788+IKIOA/Y\nZ3GBkCRJkiRJkuqaSCh0OrBLRFwITAH2iohXA2tn5pyIOAA4h9KfaG5mXtvd5kqSJEmSJGkyLDEU\nysz7gX1Gffry1v1nAWct5vH/vKwbJ0mSJEmSpG5MZPUxSZIkSZIkrWQMhSRJkiRJknrIUEiSJEmS\nJKmHDIUkSZIkSZJ6aCKrj0mSOjDz8HOX+bFzZ+88iVsiSZIkqY8cKSRJkiRJktRDhkKSJEmSJEk9\nZCgkSZIkSZLUQ4ZCkiRJkiRJPWSjaUnqoWE2ubbBtiRJkrR8cKSQJEmSJElSDxkKSZIkSZIk9ZDT\nxyRJveHUNUmSJGkhRwpJkiRJkiT1kKGQJEmSJElSDxkKSZIkSZIk9ZChkCRJkiRJUg8ZCkmSJEmS\nJPWQq49JklSBK59JkiRpeeNIIUmSJEmSpB5ypJAkSSs5RylJkiRpLI4UkiRJkiRJ6iFHCkmSpM44\nSkmSJGn55UghSZIkSZKkHjIUkiRJkiRJ6iFDIUmSJEmSpB4yFJIkSZIkSeohQyFJkiRJkqQeMhSS\nJEmSJEnqIUMhSZIkSZKkHjIUkiRJkiRJ6iFDIUmSJEmSpB6aNuwNkCRJ6sLMw89d5sfOnb3zJG6J\nJEnS8smRQpIkSZIkST1kKCRJkiRJktRDhkKSJEmSJEk9ZCgkSZIkSZLUQ4ZCkiRJkiRJPWQoJEmS\nJEmS1EOGQpIkSZIkST1kKCRJkiRJktRDhkKSJEmSJEk9ZCgkSZIkSZLUQ4ZCkiRJkiRJPWQoJEmS\nJEmS1EOGQpIkSZIkST1kKCRJkiRJktRDhkKSJEmSJEk9ZCgkSZIkSZLUQ4ZCkiRJkiRJPWQoJEmS\nJEmS1EOGQpIkSZIkST1kKCRJkiRJktRDhkKSJEmSJEk9ZCgkSZIkSZLUQ4ZCkiRJkiRJPTRtSV8Q\nEVOBY4EtgbuBWZl5Zev+3YH3AvOBuZl5QkSsCswFNgZWBw7LzDMnf/MlSZIkSZK0LCYyUmgPYI3M\n3BaYDRwxuKMJf44EdgV2BPaOiIcCrwX+mpnPBp4HfGKyN1ySJEmSJEnLbiKh0PbA2QCZeTGwVeu+\nzYErM3NeZt4DnA/sAJwKvKf5mimUUUSSJEmSJElaTixx+hiwDnBr6+P7ImJaZs4f477bgQdn5h0A\nETEd+DJwyJKKrLfemkybtsqEN3xpzJgxvZPva21rW9va1ra2ta29PH5/a1vb2ta2trWtbe2JmEgo\ndBvQrj61CYTGum86cAtARDwKOB04NjNPWVKRefPunNAGL4sbb7y9s+9tbWtb29rWtra1rb00ZsyY\nPrTnZm1rW9va1ra2tftXe3GB0kRCoQuA3YEvRcQ2wKWt+y4DNouI9YE7KFPHPtr0FfoWsF9mfmdZ\nN1ySJGlFNPPwc5f5sXNn7zyJWyJJkjS+iYRCpwO7RMSFlP5Ae0XEq4G1M3NORBwAnEPpTzQ3M6+N\niKOA9YD3RMSgt9DzM/PvHTwHSZIkSZIkLaUlhkKZeT+wz6hPX966/yzgrFGPeSfwzsnYQEmSJEmS\nJE2+iaw+JkmSJEmSpJXMRKaPSZIkaQVhPyNJkjRRjhSSJEmSJEnqIUMhSZIkSZKkHjIUkiRJkiRJ\n6iFDIUmSJEmSpB4yFJIkSZIkSeohQyFJkiRJkqQeMhSSJEmSJEnqoWnD3gBJkiStHGYefu4yP3bu\n7J0ncUskSdJEOFJIkiRJkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmH\nDIUkSZIkSZJ6yFBIkiRJkiSphwyFJEmSJEmSeshQSJIkSZIkqYcMhSRJkiRJknrIUEiSJEmSJKmH\npg17AyRJkqQHaubh5y7zY+fO3nkSt0SSpBWHI4UkSZIkSZJ6yJFCkiRJ0gPgKCVJ0orKkUKSJEmS\nJEk95EghSZIkaQXlKCVJ0gPhSCFJkiRJkqQecqSQJEmSpKXmKCVJWvE5UkiSJEmSJKmHDIUkSZIk\nSZJ6yOljkiRJklYoTl2TpMnhSCFJkiRJkqQeMhSSJEmSJEnqIUMhSZIkSZKkHjIUkiRJkiRJ6iFD\nIUmSJEmSpB4yFJIkSZIkSeohQyFJkiRJkqQeMhSSJEmSJEnqIUMhSZIkSZKkHpo27A2QJEmSpBXF\nzMPPXebHzp298wpbW9LKyVBIkiRJkrRYBlLSysnpY5IkSZIkST3kSCFJkiRJ0nLLUUpSdwyFJEmS\nJEkagz2ktLJz+pgkSZIkSVIPOVJIkiRJkiQt4Cil/nCkkCRJkiRJUg85UkiSJEmSJC0X7ONUlyOF\nJEmSJEmSesiRQpIkSZIkSUM0rFFKjhSSJEmSJEnqIUMhSZIkSZKkHjIUkiRJkiRJ6iFDIUmSJEmS\npB4yFJIkSZIkSeqhJa4+FhFTgWOBLYG7gVmZeWXr/t2B9wLzgbmZecKSHiNJkiRJkqThmshIoT2A\nNTJzW2A2cMTgjohYFTgS2BXYEdg7Ih66uMdIkiRJkiRp+CYSCm0PnA2QmRcDW7Xu2xy4MjPnZeY9\nwPnADkt4jCRJkiRJkoZsysjIyGK/ICI+BZyWmd9sPr4G2CQz50fE9sDbM/MVzX3/DVwDbDPeY7p7\nKpIkSZIkSZqoiYwUug2Y3n5MK9wZfd904JYlPEaSJEmSJElDNpFQ6AJgN4CI2Aa4tHXfZcBmEbF+\nRKxGmTp20RIeI0mSJEmSpCGbyPSxwUpiTwamAHsBTwPWzsw5rdXHplJWHztmrMdk5uXdPQ1JkiRJ\nkiQtjSWGQpIkSZIkSVr5TGT6mCRJkiRJklYyhkKSJEmSJEk9ZCgkSZIkSZLUQ9OGvQGSlk8RMSsz\nP9X6+B2ZefQwt0mStGKIiNePd19mnlxzW/ooIqZkpo1DJUlLZCi0jCJifeC5wKqUFdY2yswPDner\nuhUR04CtWfQ5f35I27JqZt47jNoru4h4FfAiYKeI2Ln59CrAE4EqoVBETMvM+a2P183MWyrUHfpJ\nTESsBawH3AvsDZycmVfXqD1sEfFwFn1/uWjIm9SZiHjcePdl5m9rbkstEbFVZv5kSLXfO959mfnf\nNbelRzZv/t8GuBO4kIXHENVCoYjYEFhz8HFmXlOr9pCdA+xaq1hEvHq8+zLzlFrbMSwRsTGwJ4v+\nrvne0rGIWAV4Kov+3L8/vC2qo1npewqwHfDDzLxnyJtUxTBf74g4MDM/WqPWMKzQoVBEPBH4JOUE\n6rPArzLza5XKnw5cBjwJuItywNOpiPhyZu7Z3H5+Zn6z65qjnE45mHsEJSS4DqgSCkXEPsABlN/Z\nKcB8YLMatYclIg7JzMOa2w/PzOsrlT6b8tpuABzffO5+4HddF46IhwHrACdHxOsor/VUygnEM7qu\nz/JxEvNl4DjgpcBvgDmUALoTEXE9MAKsTtnJ/hF4JHBDZm7cVd0xtuNEYFtgrWY7fkd5Hbqqd1Rm\nvrO5/eTM/GVXtcZx/DifHwF2Hue+BywiPpGZ+zW3n5qZP+uq1hg+TPPc2j//Sv7S/L8H8HvgAsrf\n9qO7LjzsfXdEbAYcDvwdODQzr2g+/8nM3Lerupl5cFPn7Mx8QWt7vtVVzdEiYg7wL5TXfwrl72u7\nivUfC7yMRcPut1QqPy8iXgwkZR/edeD81Ob/rYG7KfvPrSjHi9VCoYh4M7A/8CCa1zwzN6lQ+vOU\n46c/V6j1DyLiyZT95/3AB4APZOZ3KtUe1s8cyjHTuiz8uY8AnYYEEfHBps4/yMx3d1m7qf8xyjno\nY4CnUd7f3tB13Vb9Xr3eLbtFxJGZeV+lelWP2VboUAg4CtgLOAE4EfgmUCsUmpKZ+0TEXGAW8IMK\nNTdo3T6I8nxr2jAzt42ITwFvB/6vYu23AjsChwCnUt6MOhcRHxjvvgpv/DsDhzW3P0eHJ4qjzACu\nB/Yb9fm1K9TeBngnEJQwBMoBzjkVai8XJzGUQORM4J2Z+fqIeE6XxTLz4QAR8Vng4Mz8Y0RsBBzZ\nZd0xbAk8gRKWvJuy4+/Sk1q3P0a9vy8AMnOnsT4fEat1XHqL1u0jqPu8p7RuP2ncr+pAZh4PEBEv\nzcy3Np/+XETU2I8Ne989B/ggJZg4IyJe2xxYPr5S/YcMRntGxAYs+vPo2pOBxw5xGtUplAtq21Mu\nttTYjw48hEWPlToNnDPzIFiw/3ze4POV958A+wC7UT+cuTMzD61cs+04ynHbocB/UEL4KqEQw/uZ\nQzk3eXblmpdXrjfa1pm5f0R8NzN3iohar/NA317vBbWB6yLi95T305HM7PoiQ7VjthU9FCIzr4yI\nkcy8MSJur1h6fkSsQUnlR6j/s5yy5C+ZdIPRUGtl5t8jouZB1nWZeX1ETM/M8yLiPyvVvQHYF3g/\n9X/mU8a53bXjKb/To2t2ekAJkJlnUE5adsvMb3RZawmGeRKzGiUYuyQitqC8x9SwSWb+ESAzr4uI\nzkdQjPLXzByJiLUy86aI6LresP6+FhERb6GMghyMJLgXGHdq2SQY5vNeHvqbrB8Rm2bm76L8kj24\ncv2h/K5l5rcAIuJK4CsR8TzqvR7vB34eETdTft5vr1QXShAzHbitYs22OzLzgxGxWWbOjIgaFxCB\n8YPnCh4SEetk5m0RsR51958AN9Wcct2aCvyXZgrdJTR/W5WnAt8F/BpYLTMvjohqoxmo/DMf5eqI\neNTg+KWGzDwJxm6rUWkTVomIpwN/aC4kTa9Ud6BXr3fL7kOoWe2YbUUPhW5uDqjXiohXAp33HGk5\nBvhX4FuU6RbnV6g5JSJWpUynGdyeAlBpLulXmr4Mv4iIi4E7KtQcuDUi9gBGmtd8wxpFM/NjEbEV\nJZT6do2aLSPj3O7UEA8kiYjP0zzXiHht+77MHLdfQQeGeRJzIPDiZhteSwmIavhNRHwG+BFlesUl\nleoOXBIRB1KuwnyBMiy5S0P5+xrD24B/pt4oyGE+70dExN6U/dbgNgCZOWf8h02q/YHTI+KhwJ8o\nVzy7Nux99/yI2B34RmZmROxHGVW9aoXaZOZpEfFVyijUG2oMvY+Iiyi/3w8BroiIq5q7alzZbRtp\npkVPb/rFdT5SqBnp+aHMfF1EXEG5sLA28KLMPK/r+pRRaZdGxJ8px2pV9mGtkd2rRcQ5wE9ZGM50\nObK7PRX4zc0/qHAhbZQRyjT3b0TEyykXGDo1xJ95e+r7GsDLI+KvzV0jmVkrnBlWW42TgGOBmZQR\nYeNNR59UfX69I+I5mfntiPgw5X1tBDi467pUPGZb0UOhN1GmGdxEmbf8plqFM/M0WNBw+tTMrHEV\n6jGUueFQDigHVyBGgM7ncmbmMYPbEfF14Mqua7bMAjal/AH+G3VP0mdR3oRqe3pEXEh5rbdo3e70\noHbQ/6L1BkyrbtdvvMd1/P0nZBgnMa3aF0TEr4D7gFuBKyqV3ht4CWWUyhcy86uV6gLlgCIi1qZc\n7Xw+JZzq0nYRcQ3ld3tG6/ZIZtYcJVV7FOT2EXEd5bmu37pd4+/7FODhY9yuJjPPp0wpqmmo+27K\nicP7KH2Ubs7M70bE/nQ8RbQVzIz+PBWCmVe2bg96Ca1O6XVT06GU99XPAFc1/3ftKEqfTYA/NdNL\nnk650HBehfqrAI8FHgZcn61FIzqWo/6vU7S5kNbMHtg8M3/WXMT8es3tAF4BPCMzvxERO7Ho30BX\nxvuZd37BoTX1fZFRIxFRa1osDK+txlqZ+czmdpV2Go1evt4RcQhlsZ1vAzsA/wk8G3gP3Z+PVjtm\nW9FDoacA32j+AURE/DEz/9R14YjYgZLSrgKcGhFXZ+aJXdbMzH/q8vsvSUQ8gXLSvqCxN/V6ON1J\nCf4eDZzV1O5cLFwt564a9UapfeICwKAh6uANuHLt70XE04CbKVfx/50ynepjNeoP+SRmUOsLlL+r\n7SgjC/4f5aSia2tR3s+uBR4cEa/PistGR8QjgA9RruyfCmzMwubAXag1LW9Jqo6CzMyuexYtrvYi\n/TYiYl3gvszsfOp3qwfAwL2UK7x3Z+bmYz9qcgx73w08NDPf2P5EZn6XcgzVpRonpWMaTG2I0hD1\ncZl5UJTeNp+hTjAz2I7vR8TPKe9nm2ZmjRHW648O9TPzkoioNVVy38z8AmUUfTWtKT3bUMKRoyPi\nc5Q+HDV8lhIE/YxyceXlQM0RzndTLnbsSTmGWJ9yLNWZ1s98QTPc5uOT6XhxjiiLDW0EfDgiDmLh\nwiSH0/13u4olAAAgAElEQVR728Cw2mpUb3gMvX69n0NZsADg75l5TkR8G/hhx3WrHrOt6KHQYZQr\nEZdQVj24B1gjIk7IzI9UqL0DcBqly/8FlGbXnYmI1SlD3Y+m/GF8jLITODAzazT7OprhNfY+njIs\ncxfgx5Q3n90q1B3aajmZeXVEbJmZv2imG+xNeb3n1qgfpYn66G2a2XHN/2Hh/OxbKA2vr6UcbL2w\ny9qNoZ3EtGyUmZ+NiDc1V3hrTVv8KuVvbHAgX3tq0RzKwft7KCtJnESHq49l5n0R8YLM/HpETKeM\nOr2b8jff+WqSLbMoV9WrjYKMiBdn5lcjYh3Kz/tu4IOZ+beO6z6Nsu94BmVu/nGUFZIOzMyzuqxN\naao8hTL1+/jM/FFEPJWyiEGnloN991D2Y61g5pGUUUlbUEZJ/WuN+o19Wbhy5Qso7y3VQqGIeCll\naug04EtRemAetoSHPVCrt24/v3X77x3XHVgtIn7Moquevb5SbYCPs3Bf/h7gfynH6117RGZ+GiAz\nPxwR361Qs20u5bh8R0oD4BOb252JiLdRfr/Xi4j/13x6CmXl1K6tB7wKeCgLw7f7KRfsa/lKRLyH\n+m01ZlC/4XGvX+9WAHfU4OOIuLVG7VrHbCt6KHQn8OTMvKs56DqNclX9+0DXodD9mXlzs4O/K+o0\nuf4EcDslGT2WEo78GvgkdUYSDLOx96aZOSsits/MsyJidqW6Q1stJyIOAF4REc8CPkqZgnA15eC6\nxkH9F5v/p1CWvKwxR3u7zNymGYad2axgUuvgajk5iVmt2dn+JiI2pF4DwamZ+dolf1lnHpSZ50bE\nIU3fk05H50XE+4EnNPPiP065qHAF5f202tKuLFzGeTolmOtURBwObNZMAf4E8DdKGPhJoOsTt48A\nb8jMeyPiMMoJ6xWUE5lOQ6HMvBsgSpPpHzWf+1lE9x3NGf6+e2j7scYJlOf6fUr/rBNZeNW1a/cN\npi81v3e1w+4DKOH22ZSLiT9h4aqiXbk1SmPrKzLzLoCIeCz1TlgPqVRnPPdm5u8AMvOqiLi/Ut2R\niHhcZv42IjaljLytaYPMnBtldcELI2Jq1wWbthLHRMS7M3Pc1Xo7qv0D4AcR8bTM/GnN2s1+5HeZ\neUxETMmySEbNtho1LpL+g76+3pTj8tUy854sC+IMVortPEepecy2oodCMwY7vMy8OyI2zMx7arwR\nAldGxAeBDZqAokYX9i0y81nNCfOzgT2bg5x/q1AbhtvYe1pzgkxzVb/aTr5SnbG8jDKFaISSim+W\nZTWsC2sUz8z2MvBnR51lZf/e1L4rFjYGhfqvwzBPYj5Mucp5APAOSi+QGn4ZEc8Efs7CxoE1muAO\n3BURz6WsqrEN3U/Z3Ckzt4uyesjuwKMy886IuKDjuqPt2/w/BXgC8AfK711Xdmg97xew8HnXWCxh\nlcz8ZZRGuGtl5iUAFU/aAG6JiPexsKH69RVqDnvfPexV39bIzDOb22c0FzxqOSPKil8/olzcqNor\njRJK3d1cTBuJiE5H4zUOoTzvEygnqZtQRiS+puvCzcnydyLircC6lN+9o7uuO8rVURriXkQZJXZt\npbr7A1+M0sT+OuAtleouEE1/lebCVq1eTgDHRcSraK3ClZkfrFT7kc352KD2hpnZdfh9apSFSOYA\nXwHmZ+alHddsW5VyjtBe9azm71vfXu/PAXMj4u2ZOS/K1PePUXojdq3aMduKHgqd0fxQfkSZcnJm\nROxLnX4zb6U0bzyfktq9efFfPikGI3OeBfwoMwcrC3S9Ss/A0Bp7A/9BmaL3cOBi6q3INMzVcm5v\nhic+DbgqMwchXJUljSNi19aHD6cM2ezagyJiM8oV9fbtNSvUbhvaSUxmfoVykAHw3oio1dtpRxZd\nbrNWE9yBvSkj4jakrMC27+K//AEbLA6wNfDrzBxMGauyItNAZr5qcLu58vSljksOnvczgF+1nneN\neeuDfdbzKA0baabG1lxO9zWUqVwvpIzW+a8KNYe97x72qm/TIuJJmXlpRDyJuiHVlyl9XgI4OTN/\nUbE2wPkRcQrlROY4yiixTjUj4P6FchX5BZQpwbtlx/02I2Im8EbKVK2ZwKcpo6RmU6Y81PImyv5k\nN+Ayuh+ZNbBDZj51yV/WmXdQfuabU37vO58a23I65Wf9ZMrFvZpTsA+jBCL7AN+l9H/pVGY+rTk2\nnwkcGhFnAnMGI9QqOIXyM9+eEkB2vqrhKH17vY9pLl59P8oCU7cBx2RmjVXfqh2zrdChUGa+L8oK\nQZsDczPzVxExgzorGH0tM3dd8pdNqjuag7k9gVOaEVGvAa6pVP+4rLsseNujyoySmAHclJm1DiqH\nuVrOSEQ8jtLH6UyAJiSpdfXnVa3bd1F2fl37O+XKy0jr9uDzNQ3tJKYZxbAP5Q1/Tcr0tSd0XTcz\nt2zqPwT4a1ZuYAj8a2bW7Ol0X0TsTPm9/gpARGxHWfFtWKbRfRA3vwl830iZcj1YOKHGyM9vNyOx\nHgW8qJli8Qm6D8IWaObgHxFlbv4bKE1ht+i47LD33cNe9e3tlKusG1FGbey9hK+fTCdm5vaUEZDD\n8CFgW8rv2eUVemcBkJl/bn7eH8/MGv0+AF7Hwh5GtzcnUidSLp7WDIXOGMLxOQyp+W/LFcBbc+Hq\nZzVHrkzJzH2i9KKcBfygYu3rM/OiiNgnM/83It5Yo2gzhemnzcWcl1D2K2sM2h507I7M/GAzTXRm\nMxqypj6+3p+MiIsys/a+pNox2wodCjVzpF9AubL7+GZYV63hc/Mi4kWUE7ZBI73fLv4hD9g+wEGU\n/gsnURpH7tl8vobVI+LJLPqca00v2Rv4XGbeWKkeMNzVcihDwD9DaRh4cETsSGm4/LIKtcnMvaAs\n/whMy8zfV6g5WNr1tZn52SV9fYeGeRKzOzDoafQ/VGqiFxH/TGlUeSulieCbM7PW8qoAW0TEuq0R\ncV3bn7JqxZ8pc+R3pfy8q/x9DUTE9ZTQcQpln3xUxyXfSVkc4S+UIeDPpUxZfHnHdcnMDzVXVG/N\nzOuaUGhOZp7ede2BiNgC2I/yOn+FOv2jxtt3VzleGfJ+jOYgeuuIWI8yzaJmP8K/RcSRLNr0uMbo\nqIGvN6HU2RVrDvyAslLPdMoIki9mZqcXWHJh49MvNx/fFRG1ehkNDOP4HIbU/Lflcwxv9bP5zfTY\ntSjPveb55d3NSfKqzf6s0xU8xzAD+CdK2H55pZojEfEwYHpErEX9kUJ9fb3fFxEbUN5PT8mOF+do\nVDtmW6FDIYY7fO4hLNp8doRmdY8OfSQz94qItzQjZb7T/KvlcSw6H7/m9JLVI+JnlAO7wc62851d\nDHG1nMz8MfDMiNgpM++IsrLBJq2pB52IiOdQAom/UEKoDwB3RsSczPxwl7Vb3tzUHoohn8Rc3/Sg\nmJ6lsXut5SgPA7ZvTtYfQTlhrhoKATdFxE0s/BvvrLl5Zl4BvDQintr8TX0LeGJEbN9VzXG2o+qo\njWZ4+ytanzqn+Ver/mURsRNwXWb+LiKuj4jjMrPTixtRVoF6G2UE3qeBqHURKTNvAt7V7Deq77uH\ntR8bVfeFlFVEa602NzDowVdj+vNYbo6Id7JoKFWjPx+ZeRpwWjMF+UhKD4x1Oyy5YDpkloa0RMQU\n6jdcHsbxOQyp+W/LMFc/O4ZyoeVblOmKNXrUDexLWV3yMEoPxs6nC0bEmpRg/w2UVbFOBJ5b8aLW\nocAelAvHV1FxRcVGr17vgczcvQnjXgd8KyIuy8xZHdesdsy2oodCQxs+NxjRABClAXKNnkLbRMRH\ngJdFxGNGbc+7uy7ebuQVpQ/Enl3XbHnXqI9r9WIY2mo5LYcC381m9ZwKPkBZxW99St+PTSnDFL9H\nSadraIeAgwPp2iHgsE5i/tT0ZvhblGZ6XR7Et92XmdcBZOa10fHqX6Nl5iLvaRGxbZf1oqzqF8BB\nzfsqlP5V+wNP7LJ2axteShm1sjFlRNonmtvnZebFHdeeRTlxap/I1Qr53xcR+1OOQT5FnQPakymj\nsI7IzL82P/vahjW9ZFj7sXbd91esu0BmHhoRL6BMwc3MrN1o+q/AU5p/UAKKKqFQRDyactK6J3AJ\niy5P34WzozR4/o/WFP9DqTxKKjN3aq7mb0rpx3hTpdL3MbxVS2GIq581ASQAEXFqZt62uK+f5NrX\nAtdGmf798cw8r0LZqyhtHQ7OZjXLWiJilcz8PqW/zdrAI7u+WDxaD1/vtlWB1Sl/X9WauUfELpQF\naFYffC4zJzXsXtFDoaEOn4uIrSkH9LvSzPPr2G6UUVEvpJwsV9dccdqH0ofjF8Dna9TNzO819Teh\nXO19LXWu/C0Pq+WMRMTpLBqQdBkC3tmMoiAifp6ZNzS3azaSGx0C1jL0kxjKlJJHAadS5hC/arFf\nPXlui4i3U1a+2gG4uVLdBSJidcpw97cBa9BtOHM7Zcj3g5r/ofx9HdxhzQUi4nWUqz/7UFYcC8oJ\nBZl5eIVN2JeyT/lzhVqj7UE5oF4NeFlmXlah5mMp/dl+EBGXUn+KAQxvesmw9mND3382wfpmlCvZ\nb4iIZ2fmgbXqD6ZhN9vyJMp7Wy2nUULXZ1c6aTuMMiX3dxFxA2XEzplArVX2AIiIlzXbchll9Od/\nVZqOPsxVS6GEUF9szouupUJriaa9wEHADZSZBF+hTOt5Sy66gm0XtV8DHEE5VvkiJfycFxE/ycyu\nFwd5bDOCf4OIeE5mfjsi3kZpc9HZaKGIeCJl8ZOtM3MepcnyERGxe1boHdbj13uwDedSQpkTgX+p\nNH1s4EjKRcs/dlVgRQ+FDqU096o2fK6ZyvEqyo79bmAdypSezhvhNj1dfh8R52VmZ78UY4nSz2Y/\n4KmUE6ftam5DROzW1H8W5aDjKYt/xKRZHlbLmVuxFjTBU6N99aHzVc8i4vPA3oMQcAiGdhITrRWB\nWu6mLGFd46T5tZQ+Vu8HfkOdxuIARMTGlPfUV1B+z16RmRcu9kEPUGb+EvhlMy2y6vtp483ALq0R\ngL9sps7VGq1zU2ZeXakWsOAEfTCC4HLK++rrIqLz0a6ZeT1lFOQHoqzM9OYmnDmtYkgwrOklw9qP\nLQ/7zx0y81lN7aMoq5dWExGrUEbe7ke5kPWpWrUzc+uI2J3yu/6rrk/aMnM+cGBEfIgS+N5UcYRz\n2wHA05uT9unAudSZjj60VUsBMvOHlGN0YMHfWtdOprTyWI8ymvylwJ+az3c9LXl/SluLB1MayT+G\nshp051OZMnPQJ+sLLOwDOI/ye9bl+/xRwCubQIjMPKMJYI+mwipc9PT1bnlnlgVoNqgcCAFck5nf\n7rLAih4KrZOZn2xunxkRnTfKpFzR/Tzwmsy8IiK+WSMQGuV1EfHvlCUAp9Bx742IuIRyUno8Zef6\n9VonURHxb5TREr+gJMRTM/ODNWo3hrZaTixcEv76rmuN8vSIuJDyu7VF6/bmFWpfCFzcXHWo+UY/\nMMyTmNorAi0QEY/PzMspU6k2BR40OOioUPtMyk7+M5SRQV/sOhAa5U2tQK7z99OW+8c4YTqWMke+\nM830DoDVIuIc4Kc0QU2FacjtJpxJOaisLjO/A3ynmWLyuq7rjQrDRut86jfD24+NV/eLHddtWzUi\npmbm/TR/3zWKNqM13kL5/boIWD0zH1+jdmsbjgE2aOrPakY0HFSh9P9RLiycQFkyurb7ByftmXl7\nxanQQ1u1FCAi3kIJxFal/K7Pp4yS69IqmXlCU/9lmfnd5naN5uJ/a0bA3daEnnc0tWsGkWtl5tcA\nMvOUZlp2l6Zm5k/an8jMC6Ne78m+v96PirLq+S3N1L29K05fuyEijqM0kh8cs03qogkrZCgUES+k\njBh5VTOnEEoviBfT/UHOxyhLyW4cEZ+iwuiJMbwC2Cgza03n+SHl5/18ypDUmju6Aykh3KebHW3V\nYcg53NVyxps21HVPgic3/69HufJRTWZ+PCK+ARwbET+hrNQzuK/G6iFDO4lpel8Mwhla4cyvuqwb\npbfKByLiGZl5K+Vq9qcj4l2ZeUaXtVvmU6ZxTaXygTRlKtOmQwj3p0XE2q0rjlACmqkd181R/1eT\nmScBRMQ2wDMy8+iI+Bwl8O9URHya+r9bA7VWpBnTsPZjQ95/DnwRuCDKQg3PpFzZr+FKylX9p2Xm\nbRHxzUp127bMsvIZwFHNBZ7OZeZTmr/xvSLiw8CXM/NDNWo3roqII1g4Ffp3leq+g7Jq6cMpi9/U\n6DXa9jbKtLVDKNPP969Qs91Tpb0gR41+Ru0R3LX7tA3cE6XXy8WUXpSdT8kd5/M1RoWBr/d/As/M\nzBub4P8MYJtKtQcrQD+s+X/Sj2dWyFCIMmpkA+DvLDywvZ8KO/ssqy99uJlONYuyQtGHgM90ffLW\n8nvKc68iM98aEQ+iLH83hzJHe1/KFf2u+45sTBmeeFSUbv9rRcSDm5PXKrKsljMlIp5B6XPy14jY\nIUujty4dM/qKQA2DKSUR8bnWAWXN+r+LsoTwp4FtWXh1t/PVQ8Y4idmESicxQwxnDgS2HfxNNVed\nnk3pBdF5KJSZL2rmqc+kBNBrR8TzgG81V/e79nPKAVXtUOhY4PSIOIjynr4JpZH7x7ssOsxgpuXj\nwCub2+8B/pdy8talwfHBvpQRiRcAW1MO5Lu2amZ+CspqTLmwCW81w9qPNXW/BeyaZRWVWifog/pH\nNCPiHg+cWPE4bSblGPE7ETGXMp2qtmsi4pGZ+aeIeCgd9qIYw88ox2+PBnYBaoZCe1FGae1CGeU+\nu+uCEbEOpZH51l3XWozrMvP6KCuXnhcR/1mh5qbN6NMpo27XmAa9fURc19Rbv3V7vQq1B2YBH6VM\n3/oN5feuS9+MiI8C78vMW5vRKv9FmcVRQ99f79sz80aAzPxzRHQ+hWzwHk6FHr4rZCjUTF06KSI+\nU+mkYaxt+B7wvYhYlzI8+DO05vJ2bDXg0ijNMgdDyDpdmam5in4S5ef+eMob4S+BR3Zc927K/NVT\nImKzpu4vojQWq7n62WmUpomDg6oRylWoLn2YJgiJiKMy850d1xut+lK6EfFgygnjZsCOlUYHLaI5\niVklIt5KWbHmtxGxWmbe03HpYYUzd40OdzPzhopD7gfv6YdGxH8Dz6X8nc+hnFB07ReU5r+DA4yR\nzHxc10Wboea3U3qkbQxcDRyd9Va5G0YwM3BvExCQmVdFhZ5d2fRTiYh/ay7uQBlB8n9d16Y0Tx/0\nkvkOdZbHHssw9mNQmoG+mEX3JZ2+t0fE5pRmw7cD76oYBgGQmV8CvhSlX9qbgE0i4ouUC4hf67J2\nRFxPeW3XAF4SEddQjtWqrMIVEXMovfBOB/Yb/K1XqLsWJRC6A/hkrfODiNiP0kx7fkTslx33blqM\nWyNiD8riJG+hTjP9I1k4ovy9rc93Hkhl5jCC1tHbcGVzQW8K5SJm18Hr4cC/Az9tLpTfTDk3+2jH\ndQd6+XrHwmn30yLia5Q+Rs+g9P3s2gHNv+NZODqok4vlK2Qo1PKuiHgXlXrrtEXEJzJzvyxd5j/e\nXH2rpeYVlwWa0RtzsqwUc2BEVFmlZyBLD6cPUU5gXlCzNvCwrLNKTFt7auKTKteG4Syl+wtKH4I3\nDivwbcwBbqX0RtiRckL3+o5rDiucGYmIB7WnTzUHG7WGIw9qHpGZ/0ZZvvjsiHhIpdKvoqz81dmK\nIWOJ0gPgnObfgl4nlQJIGEIw03J1c5B1EeXA6tqKtdeOiJ2BHwPbUU6cuzZlnNu1Vd2PRdNfhRJE\ntaey1Bj5+UnKCdT6lAssb+i43pgy8w/Ae5pRG7tRAu9OQ6HMHLM/XTM6sIZvAvtmZu0pHidRpu2t\nS2lIW6NfF5TQNygLz3yG7hvujmcWZZXFgykh1dsr1NwzM7ePiE9m5r4V6i3QOlH/B9l9f7zBNnyM\nMhrtMcDTgL/Q4XtNM8r0Q80/ojQ8/mtX9cbQ19d7rGn3X+245sD/AGTmTl0XWtFDoVdSt7cOUZYc\nPIQydO2lrbtqLAXYPikdoUx3+GlmXtV17cb5wEeirObwacpw/HsX/5DJ0UzXO4Yyb/VUylX1mi6P\niI0y87qKNYfV/wJYdCldgGaefNdekpk/a9Vcv8IUxbFslpmDURNnVOrFMKxw5mjgG83BzVWUfkoH\nUXop1bRFRKzbBO1k5g2V6l4D3JL1V5JI/vFvfBAO1RiKPcxgZi/KcsnPpxxQH1ax9kzgI5TRiL+h\nTlgwMs7t2mrvx06NiONqHMyO4f7MPBsgIqqtpDgQY68mCfCNytuxOiW0eBslAH1ihbLXABdGxCMo\nU2P3ycxfV6i7YWbuGRFTKBd0armrCfJvinoNfxeIhYuSDMygBFM1tuXeiPgxsFlEbNm+o0IAXb0v\n3hi2zsz9I+K7mblTRHynRtGI2IEyBX2ViDgVuDozT6xQupev92Da/UBzHvxGynT0k8Z6zCQ6mYWz\nRg7ODhdbWtFDoaq9dQAy8xjgmIh4d2aOm1p2ZPTqT2sDh0TE0ZnZ+bLlmXkacFoTDhxJabq9btd1\nG++jTG04jbKs8AVAjTfAgWdT5uff2HxcY1TaI5oDyymt28Dkd5wfSzOVZ1/KgcWawG8p06k6MwiE\n2iFg5R3ewBoRsWZm3tkEMzWa6I0OZx5NmVLWaTiTC5c0nQVsRAlcD87Mqks3A1tQ+pzcSDlxrjXy\n8+HAlRFxZfPxSCsQ7Exm/lPXNZbgTcDelNELtYOZeylTPG4CLqWs7ldlBZHMvLwZ5boF8NtKF1We\nEBGnUN7LB7cH29Pp1O9Rau/HtqJcSDqbMvrzzx3WWpyum7ePZbyLKLVWP9uYEgS9gvJ794qst6rj\n0cCsLIuDPJUyaqvG1NTB1MSRiBjGaw7DGQk4rEVJoCyD/gjKa/zWjmuNVntl3rGsEhFPB/7QBII1\nVqqFsr8exjlRr1/viNgC2A94GfAV6lxUar+n7AIYCo2j3VsHygFOrQOsY6KsqvAEysny+7oe0ZCZ\n/zBdKyLWAM4DOg+FIuLRlD+Al1JWyXl+1zVb7s/MmyNiJDPvanpxVJOZXS/rOZZTWHhg2b5d60rz\niyh9CI6kDF88tlJdGH4I+DHg5xHxa8rJY4350mdExF8oK5ZsBPyBCuFMcyDzk+bfIp+vNI0JgMx8\nTK1ao3Q9LXBMEXER4/wtV5ric0Zmjr7CXMvxlNV5dqFM4zqZEk51LiLeQTmJ+iFlGvSXMrPrfgwv\nb93+/+2deZhlVXX2f93IDJoIKoMEZHplEFQQB0BGB1RQI0HIpxEQQQxREczH0OSDQADFESWAMs8I\nqIAMRkFUQFEMYyIvIqMiRMEAMgrd3x9rn+7bRVdjTJ21b9Xdv+fpp07dvrfWqbrnnr332u961zE9\nxxqX7HHM0Vlv95Lkv0rSNQP/1/dcbamioOhMSWdf631745UYB3XHkt5OzBVtu/eSA0WzhBcQpUxr\nE01BshJCEMqZmyA2eiSlKMqB6ZIWJJKA3fG0ch59jmVVk76Dqu6ShBPwH9170DNblK9fLHEH6VvR\nXzMZ1nEKMTfemShTPTYpbq010Ui+36Uy6O+JvMOJgGz3bSrekaYunuxJoSreOoXjCYPGMwjPkZOI\nRXQq5WaQtXA7j/BWeaPth5Nidtwm6TBiorcPSeVjkmbYPkTSmYz5YPY92HeTSknvGDSmlLTd+K+a\nUH5j+0lFJ4vbkmXRVQY8RZeYjluI0q1bgTeT093wR8CPJK1DlLdk+NzULmMCQNIrCeXKbI8X2xll\nH4sQqsuZxO7b4eR0SNr+uZ/SK7+XtA1xfaeY/w6wiu1dJG1s+8JyT89iB2Bj20+XRePV9G/Secdz\nP6U/ao5jisYUhxKbV6f0GWsM/86cRcR1A8eZC0bKvGU1ovz+A+Wa3zsh9NPAokSCJEud1N2vn5J0\nJDFH3oDw58tgJWI863bWu/tZ32PZUCR9JR1MlJn8BPiopG/YPqLnsNUW6mMtDmpg+1+Zs2H68fk9\nd4KpsiZidN/vU4hE2GdtPzDGPqZvlpL0JuJe3usGx2RPCl1HmA6vSVHrJMZeyvaR5fh6SZmdsGYj\naRlg8Z5jdO3w3kd88JcpcTMXER8myluuJMoOdkmK23UCSh/oJb0D2BDYQVKnHFiASD5+LeEUflUm\neY+WwSerVBDqDXjrE6VypxFJoHQpuKT9CRXeT4G9ipLhC33FG4Iypo6TiFK5zLbJEMbmHyU6aRxM\nLGC/13dQ23cBSFqVkCJ3u9rL0X9bWwjz3z0Hvs8w/+14nqSlCR+tJSlJqSSm2X4awPYfk1QMZxN/\n36WJ8oKbiXnL/YQ5ad9UGcfKvXs3ogPVRZmxh2HBWHij7Q0huogCvZfl2t5G0gqEeuEawlz9rcC/\nud8GDt1Y0qlO1yXKQlM6v9leKSPOPOJ+H6B4Gb2GHPP6ebEVsIHtmZIWIPziek0Kjfc5U44HZRer\n67Y3jTCWv932WLuNiY55bvGv6mJ3zLK9fJ+xC1XWRKP6fhMG7jsBPyzVSRmd/Tr+nfCFg543OCZ7\nUugE4PvA6eSrdRaVtIzt+yS9hATPkXns8i1CdIbaq+fQXTu8Y5jzQYTcRcTfEl3mOvn5tpLusX1l\nz3G3Bm6w/X1Jy9rOrGm9AViK8M3qDNZmAmcmxd+NKB87hzBUy/S+qDXgrSNpbSIBug+x03ma7dvm\n/8oJ5R3AhmVi9zzib9BbUmgIypg67rN93HM/bcJ5ArgRWNj2lZKeTo5/BtG6eSOipGqJjKDFFHMp\nYBViUpXSrrowgygJXZZYJH8sMfaVks4Ffkh47FzVd0DbrweQ9A3g72w/omifnXUvrzWOrQes79zu\nOHOhaNCxL7Bw95jtNAUksKCk6SUZM7vLYN/Yvgc4qHgDvoUYQ79CeNX1FfOAsY9J2ooou+gdSScy\n/liWoTo9j0i2dxsbs4g5RBa/IpLODxGbDPdnBVYFD8oOD3Tbk7QicGBC2EeKsvzShFjzotaaCBi9\n9+pgnqIAACAASURBVLuMmYcCh0raAviQpDuA8/pWfmZucEz2pNBStr9UjrPVOgcQ3RUeItpQ9mb8\nNMDYXb7HgZ/b7rW0xvYnyte5Oogo3O+z2J648XSdchYBnpH0M9t7zveV/zs2Z44B6+nkJcG6Sd3J\nkk4tD00HXk9Cp7vC4kQ5z3JEC900fxkqDni2byYSQt01fpikFWxntfO9n7jW/0AMuL+d/9P/19Qu\nY+q4sygLrqNM7DO8PwonAZeWMSS7jfIfbB8maTXbO0v6YUZQSX9D3Nt+Dqwt6UDbp2XELjvrkvQi\n4HeONrsp2N67eLysAZxgO7Mb1Eu78dr2o4m7q1XGMdt/kxHnOfi/RFIsW4HYcTbhp/Rj4LUklCGP\nYUlip/kjJClYJL2AMLLfjUhUZCX7u7/t7kRZ6FWEcmeDpPjLJG+kjGU54FZJNxBKxKdUOqcmnFdN\nD8rZ2L6rlKz2zauJOfJpxLUGucryWmuijlF7vwdjXgZcVjbV3t93vMyN28meFEpX63TY/g6wcpHA\nP0AsXnsd+AYkql+2vUf3uKRTbNcwS/0MeYPtgsDmRT0xHbjY9lvVf6vwaeMcZ/I5YuG2IjEQ3U+O\n4/0JwCWECu8+wkdrk4S4UHnAKyUtf03INLuBv++Y3Y3/xcAvBiZ2ve6yD0EZU8fChHFhZ16Y5f2x\nPfA6osRmc8avme+LWaUcd8miHklRChHqz/Vs/6Fc75fT83VefMkOJZoVLAw8Apwl6eCupKtvJL2M\nUEdNJ5Jha9v+dEZs4N8kfZ8or9kA+GZS3GEYx2pxe7LScy5sf1bSt4n72nHOac0OxNyQUCD+N3NU\nSr2VKypaVO8BbAqcS6g/t5jviyYQ298u57HXwGf6KklZ7elvkbSc7XuT4o2lZhK2mgflmCqKZUlQ\nSNlet7KqvNaaqGOk3u+B2M/yvkwgbeN2sieFZjC3WudD2SfQSe5LLXGvSPp74nd+oaS/Jgb5aUDa\nJGMMmZPLpYib4JPl6wvL4wuP+4qJYdY4x5m8xvbHJX2vlHxclhR3KdsnSHqf7auV2+K1yoCnMPHe\nnkjAnQd82PadfcYcoLZip0oZU5EhH1fDA0Rh6P174CLgk4Qy66fJp3EQ8C6iU9Dt5WsGMx3doSjl\nTE8kxPws0VZ2DYeB/POJv/tnyDPpPJ9oJfv7pHizsb2/on3x6sAptm9ICj0M41gtHpN0CXA9cxSI\n+2UFl/RSonvlWoAl7Zk4pii5VO4nxGd5LdtPScpU4Q2yhKTNiXv5G8hbwG0E3C2pU/fOsr1cUmwI\nc/FPERtL5wA32r5m/i+ZMMZ6UL6g74AqBvpEFcXywK+JcvBr5/vCCaKyqrzWmqijpufoYNVM2vtd\nOIlk78vMjdvJnhR6ie2VJS2d7IcwL3qfaNk+CjhK0n62D+073p9A5uTyKOBGRYvwlwOflrQf/dfz\nrlcSEdOANQeOZyXKhBcoC4k7SzZ+yaS4XeeYbmKb6bVSa8A7i+g6dgPwCqJ+GEjpNtfd+P9pHv/9\nz33GLlQpYwIeBM5XmAceC1zYsxkqAJKOICbxzwP+q5zHrwm1TGYnyQ08pyX6BYlxb5f0WWKH843k\ndFxbb/C+6ehieYCkKxJid9xj+8DEeLNRmP9uQSxSV5P0TtsZn+1hGMdqUSsx0fFV4Gjic7YpobjN\nUs/8RJJs+7mfOiFsRngX3SzpHHpugjIfdiYMllcjyu0zlNXYXj0jznz4CpF4P4C43k4mVLC9ofDs\ngiiheoYwFZ9WzqVvNgcOKV5pl9tOs3foqKEqL9RaE3XsBqxAoudolwSs5PHaUcv7EhI2bid7UmhX\n4PTMhJDm0dKVuAFm7sacKemjzN26uTf5+zj1jNOIG1EKto+X9E3CAf42R0vABWz37f+xTs8//0/h\nFKJed2fg08TCuTckvcL2TYT564mE98a5hCdBFrUGvM2e+ym900lhpxFS/yyFVpUyJkdntS9IWp/o\n7nCopK8DX7V9d4+hN7b9OkmLArfYXhFAUu+dx8bwNkmfT7iXjWUnYmL3JqI8NaMt/JPjPJ7ZfexC\nSYcz4M1mO6tV+jnAd8n3txmGcawWpxOLlr8iSiRTOmENsIjtLtn7TUkZfh8dDwE/lfQH5iQBe1Ou\n2L6aUO8vSSwSF5N0FXCq7bTOd7ZvkbQXkRS6gUj2946kLYl11XTgS8ABts/IiF1Y1PblZfHsJPXn\nYNenHYiFa5aherWy2Mqq8mprooEk4CAPEZ17+/Y7rebxOkBN78veN24ne1JoYUnXEZ2ZZkL/u/mM\n39I1s9Vrtvy9K2v5y8SYcyHpdcQiZkFgWqnbfkvfcQfUG8/ycQJSfJxs/ytzTNwySizOkXRMWay/\nPiHes6g14HW+XTWxPVfSr5Q+ZFCrjAkA29cC10pamNjpNLBojyEfL3Efl3T7wOOZCQqAFwH3KjpZ\nzKJn9UZJ+O1EGJkfnaHKGmCapE76PEhmaer2RBKsW8xkKl4fsT0jMR4wHONYRY4hdlXfRJQTnQK8\nLTH+87qNFkmvSIwLsWh6YZZfV4fDTP1Y4NjiwZFq7SBpD+DdhML4JCI5tMf8XjNB/AuRDDsK2BD4\nGpEkyeIJSW8h1OWvI0presX2vt2xpNdllmZStyy2mqoc6q2JeHYSsOugOaWTgAPU8r6EhI3byZ4U\n+r/ZAYdh0Uiy/H1gQnm67Y2y4o7haEIlsy1wE+H90Ts1fZyKYmGe5VI9S/7XB46QdCmwo+37eow1\nTyoOeNWRNChBX5bYicqgVhkTMLu05n3AdsSi/e09h1xEYTo8fczxYj3HHcs7kuOdDNxGeACsDmRO\n4lcikn1jJ3SZE/onbe+eGG+QmyVtz9y7jLf2HbTmODYErGJ7F0kb276w7PKmUDyz9gVOUHSau5fc\nBMmtwEtIUsp0SFqLWLDMJHb2P5UZn0j8vhG4zPYXJWX5xD1GKH2fdjTAyU5U7Ep4Oi0N7E10Ycsk\n+/etWRZbW1VeZU00jyTgvvN7/gRT3RvP9k5ljr4qcCNxT8/iICLZ3dvG7aRMCg1JXWFNasnfH5T0\nMeZWZmVlSH9n+0xJb7Z9oKKDS+9U9nHah/AjeDeJfj7FfHZ3SZsQnTuuGfi/3ndAClUGvCFhUCn0\nBLBXUtwqZUySdiQ8H5Ym/Da2tN1rx7XCM4RqAOLzNXicybPMQYG7eoy3tO1tFc0RsrryAGB7pcx4\n43CXpH2JNt3Z8u9Xln8di5CgxhxCP8JMnqfoEjurlDWlKOOKWmUv4vP9D7azvD4G2ZAod3iAOSrE\nDOPjrwIfBf4JOJjoOHh5QtyO6ZTft3w/XtnqRPMwUeL+lZKI/a+kuB172q7dsCKTamWxQyAQqLIm\nGsMoJQGBqipEbP+A8AqDnjZuJ2VSiOGoK6xJLfn7A8Tu/bqEeuEu8mRzM8vu02IKjeYLn+sFE0yq\nj1P5+ddIOhVYx/Y3+ow1FoXB9KHAFcxZLGcyDANeFWxvBiDpL4BnihQ/g9QypgE2BWbYvioh1mwq\nqh7Hkm0O2iX0Zym3oyCSTmSc8cr2zkmnsSChkOoUeb3LvyVtTXQseRrY3/ZZ5fFs/6r0cWwImAFc\nRaguf0xel7u/JUoMnk/s6KYnhWyvlh2z8ASR3F7Y9pWSshPtZxD30hUVHdC+mRR3O0KZ9p9lvppt\nSLumpL+w/d9ZATXHZ3UasJak2eVyfW8idlUMI0rtNVENhsEbr5YKkYG5ecfDtl853vP/HCZrUmgY\n6gprkip/l7Qm8GXbm0u6heh+9VLm+Nxk8AmipeuRxIB/fGJsqNTG2PYRmfEAirx+N2AP2xdlxy+M\n3IAn6dXEdb0BUVJ0LPB7SXvbvjDhFLLLmACwvSOApOWJNrZPE6XBX7J9fV9xi0nfeAmKN/YVdx5k\nm4NOL74+0weOpwHYfqrn2GeVr7sT3WquAl5DXPMpVJJ/708ohKYTnm0L2z45Ie5YqoxjNSk7+pL0\nImKzIWsT7YnyefqdomtoOsXD6ARivnYfsLPt65LCnwRcKmlbQpWZhu0vS7oMWJtoInBTn/EkLULM\nmY4EHlZ0XnuSKOHKLL9fE3hA0m/JU4YdM85xo1+qrImGIQlY2RuvlgoR5jR3mgasR7Snn1Ama1Ko\nel1hZbLl758C/rEc/8b2ZpJWJXZBzusx7iA72+7KaNZLijlItTbGFVgPWD+phGc8aicBa3AE8AHb\nf5T0L8BWwC+AS4CMpFB2GdNYzgAOBP6e6Hb3efqt29+xx5/9PyHbHHRF5vb16TxtZtFzF03b3waQ\ntNeAQuUqSWllbJXk30/Z/n2J/07gckl3kz9/GaVxDIBSBn0UsACRkLvLdvZ4Umvz8khgF9s3KAyf\nOwPkvtmeUDteSCj5U0uaJK1DtAe/h+hseajty3oMeSRh3D+d+Bv/lPDrOpq416Tg0kEzkyEooxpV\naq2JxksC9j6WDYk3Xi0VIrYHE1BXSTpsomNM1qRQ9brCymTL3xcrnYEgWg9i+zZJmddPuix2DDXb\nGKdie8Kzz38GtZOANVjA9o2SlgMWt/0zAElZ3aGyy5jGMrPE3d/2WZJ6NWS1/UsASSsD76GYmgPL\nEYmpLFLNQW2/rM+f/yeyhKTNicXTGxgoZ0qghvz7TkmfI1pUP1ImtN8mzL4zGZlxbICDiff7PKIk\n+ipyNhm6XfT0HfUBptm+ocS8PrGMaxFCnbRn+X5d4HNJsSEWq3sQxqz7E/6EfSaF1rK9YVEMbQxs\nWzZ3UvwAO5/VARXHbBKvtUYuVdZEXRJwHLXOD8Z94cTEru6Nl61CHKQkgbrP97L04I83WZNCw1BX\nWI0if1+AmGy8HrjmOV7yv2V2W2jb7xp4/I89xx2khix2kJptjEeR2knAGnSfp7cC3wUopT1LJsXP\nLmMay4LE5P0HkjYjz1z8TOBbxMLxfgbud0m8B9i9U5JkUZQDuzK3v0yWr8/OhDJuNSJB8YGkuFBH\n/r0z0VmvU/beU67xzM4tMJrj2EzbD0qaZfsJSVkebdsNHNcqq3lG0juAHxL3t6xShwvLv1plik8Q\n6oGFbP9YUt/la901tSHwE9vdWJ49lhwDLE9yt7lGFaqsiYZErVPNG0/S+oTKfDFgK0mZ86ZbBo5v\noAefukmZFBqSusJqSPoCMbFbEXg1UbO8Y48hfy1pA9s/GTiHDUisla4hix1Dqo9To3oSsAbflXQV\nsAKwjaRVCHPas5PiZ5cxjWUn4E3ELv47yUsUPGb7YEkn2N65eA1l8jzivb8F+KrtK5LinkRcX/ck\nxZuN7VtKCfSawK22b08Mny7/tv008fcefOx+8kyPO0ZxHLut7LAuVfzyUkpih6SsZmdChXgYMWfs\nVX05wK9tz0iKNS9mEQ0yLpa0Hf1vYP5B0q6Ex8fpCgP//wPc3XPcjs2BriPz5bZHrfnOyFFrTTQM\nah3qeuMdTcybMr3CUHTOnEas+39NzFteIekB2z+fqDiTMik0JJnKmrzG9sclfa/4+/Qpi4XwE7qg\nxLmN8J3YAti657izKYvUnRgo8bD9lqz41G1jPHIMQRIwHdufknQB8JDte0tS6CvO6zyXWsY0D+4A\nrgNeSyh2XgtkJAtmFhPaJSQtSnhRpGH7s8BnJb0G+KSkr9he/bleNwHcZzu7Ow4AZZdvB0Llurek\nr9n+TEbsMfJv274xI+6QMIrj2EeI5MiVwKPkJUaqY/suSQcxJ/ma5RF3oaRDmLtM8Yz5PH+ieS+w\nge2LJW1K/55GHwY+CVxs+yRFt8H3kbexMerNd0aOIVgTVVPrUNcb7+HsJhGSViOSQOcTmxprANcS\nG3rvnMhYkzIpNCSZyposIGk9wqdgIXouL7F9R1EGbQ28jLgYD7D9aJ9xx3A0UVqyLXATeaUlHelt\njEeZIRjwarFQSQgtSJSRPSlpuu0MX6EqZUwDfIN4v5cnTGHvJUq7+uYQotTjTGJn9/SEmLMpiaj3\nEAuIacD/Swp9Z1FOXEd+gmAHYGPbT5dr/WoiIdkbkl4AfJDYXTzZ9s8lvULS1SPiRQijOY59y/ab\na59EDSomX7cjNhAXLt/PIhR6WTwFbFY2kG8lmib0yYsBAS+WtCXwJcLvY32iNLlvRr35zihSe01U\nU62T7o0nqRtDHpK0H/Az8uZNnwF2GNzAKiWxr7I9oeXQkzIpNMBRkj5NdCm6FTjY9oOVzymDk4l2\n8DsDXyShXt3248DX+o4zH35n+0xJb7Z9oKRUaXYFH6dRp/aAl46kTwDvlbQhMQisSOwKfB74WMIp\n1Cpj6lja9uslHQf8A5DVkWqRstEA8A1J70mK2/EIYbj8d7Z/kRh3YWIho/J9ZoJgWimpohiyZvjT\nnUNsaLwKWEHS/UQCbu+E2EPBiI5jv1d0fDPFmNP2rfN/yZQhPflaeMp2TUXWCcD3iQT/JkTp5jY9\nxjuGaNCwEtE5c3Wi/PoScpJCo958ZxSpuiairlqnhjfeDuXrQ4QX4moDsfueNz1/HormZwhfowll\nsieFjie8Ac4g58ZfFUnrErva9xPlc53T+4+qnVQeMyWtBSwmSUQ74TQq+DiNOrUHvBr8DdGJaRbw\nt8Bqtv+7TPB6p2IZU8dj5evith+Pj3l/SHo70V3tfZJOLQ9PJ1Q75/UaPOIvQaiTridK504vHlo7\n2H647/glQbA6sCqxk35v3zEHuFLSuYQB7sZER6i+WdL2fpKmEQmCO4FX2v6vhNhDwYiOYy9mbu+m\nWYQHyyhQI/kKoUL8JHOXKV6eFBtgKdtfKsfXS9q253jTi4fU9yVt1t1TlNftbaSb74woVddE1O1k\nme6NZ3snAElLEwqd70jaAzgtIfyzkj+295X044kONNmTQkvZPrIcZ9z4a3M0sbP5QqLU4lXAbwkH\n8qneVvYTxCT2SOBiQp6bSbaP06hTe8CrwSO2n5H0auB2z+m8luIRULGMqePrkg4AbpD0I8L/o09u\nBpYhOvJ0XhszCS+IDA4HzhmcSEnahejKtVvfwcuE5t3EZ+skYudrj/m9ZqKwvXdJyr0cOMH2xQlh\nnyixZ0l6HNjGdraZem1GcRzbCljD9nWS3gVcVPuEEhlMvm5ETvIVYhGzDnOSFbOAzKTQopKWsX2f\npJcQ5ch94qJw3dX2jgClNDfFjDbRK6oxPNReE9XsZFnTG+9MokIH4EEiKfSOnmNeI+kjtv+1e0DS\n7sBP5vOaP4vJnhTKvvHX5inb3wGQ9LGu1EDSH+qeVn9IWhP4su3NJZ1H1K8uRH7HnFQfp0b1Aa8G\ns4pyYyeinW9nMJe121iljEnSCQPfLkAkZu6l544xZSJ9vKJr5SrE5OYXtm/uM+4A63qge2Y5p+Mk\nfTAp/vZEm+rLbH9R0k+T4iLp+cCmROn3SyX9OKH0e3DS+sAIJoRgNMex04hE0HVEWc92hBJzFDiY\nSAatAZxkOyUhZvv9g99LelNG3AEOAK6W9DBxje/ac7wPAVuP8f77FTF/aTQmjCFaE6WrdQao6Y23\nuO1vQZjnS8ook90XOFnR4fAOotnTL+ih2/pkTwp1N/6HgOcTbTenMoMDzuCEdnr2iSTyKaL7GcBv\nyu7mqsBxJJR4DJDu4zSKDNGAV4MZwKnE7uK+kjYp32/XZ9DaZUyEGedixOKt80LI5ENEIu4aYIak\n02x/PiHueEmvrCTgdGIy1SVLnkyKC/meH9B8N2A0x7HlbZ8I0R1H0vdqn1AiF9neiCR1lKT3EwrI\nR4ly6NuBY4F1iQRwCmXzdGVJS9v+XUK8mYTx7uBjGWUljdFjWNZE1dQ6lb3xnipJ7h8DGxDePr1S\nmjptK2k54K+Au233Uu4/qZNCgzd+4AHiwqjSYjeJtSSdQXwQBo/XrHtavbKY7WvL8UMAtm+TlHLt\njriPUw2GZcCrwe7AfxCf6SOBRQnZ/67EANQXVcuYbK8jaW2ibGsf4jN2mu3b+o5deD/whuK50Zmx\nZiSFHpS0/sD9DUnrE5LkDM4g/tYrSrqYaHmaRbbnB8wpZflL6nRMqcaIj2OzJK1u+9Yylkx1Rfkg\nD0r6GHObbPe5cPsk8TlbjhjLlyXMlnfsMeZsStnxrDGPATBCid/G1KbqmmiAamqdyt54uxBm/UcS\nfkp9qxAHOZFoEHKhpK/bvmOiA0zqpFBHtxNQDCSnMoOKgWPGOZ5qLNod2H7XwONZhomj7ONUg2EZ\n8GqwPnG9n06uYqZ2GROlZGsfAElvBA6TtILt1yWEn2b7j+U8/ijpqYSYEF2vLpB0BfBL4GXAlsDW\nGcFtf7l4yqwV3/qmjLiF9NLvzndD0ulFPTFKjPI49nHgbElrEEn3zEl8bR4AXln+Qf8LtwdtPwA8\nUDwB97B9YY/xxrL9wPE04vddmFwVZKPRJ7XXRF3smmqdmt54mw7+3SV9lKQyUdtvKaX3WxGK/kVt\nv2oiY0y1hVam0VU6pbvBqPFrSRvYnm2oJWkDkgz8GEEfp8oMxYBXg4qKmdplTABIWhL4a6L15+Lk\ndHUA+JGks5hjxpoyubF9Z7mXvZ2oEf8JsH+RCvdO8a86nGhJf7Okvfo2LJW0jqO16gxyPT8GyVZP\nDAMjN44Vw/7jCYn/wcTm2ZLA8sDPKp5aGl3HnEQGLQ7uSk4IDSZ+PwSsbvuTkv6NKMM+db4vbjQm\nB7XXRF3MmmqddG88STsQJe6bSeq6V04HXkFSUqg0StgSeC1wN/DtiY4xKZNCks7k2QmgacTEujG1\n+EdiN/0y4DbiPd6CpN10RtPHqSZDMeDVopJipmoZk6TtiB3eFYkSwQ/bvjMh7tm232t7T0nvJMxY\nz7J9/nO9dqIoZse1yiJPAQ4iVGkbEb4+m/Uc84uS/orwE9oPuNz5LeGz1RPDwCiOY0cAHyjqv0OA\ntxJziEuAC6qeWc9I+g1zVDKLEZ58ywO/tb1Sj6FfKGkz4rpacmDxlN2SfnciGQiRdP8BLSnUmBrU\nXhN11FTr1PDGuxT4DbAU4ZMGMa7+MiF2x2GE6vFw4NKBDsUTxqRMCjH+BTCVy6hGEtt3lKTA1kR5\nxbXAAVm76Yymj1NNhmXAq0YFxUzVMibgLOAW4AZi1+XQAR+IPrsEvag7KImgtGTQkPCo7UvK8UWS\nPtF3wDJ5XJiQm28KfFDSdOAK2wf3Hb+cw1zqCUnLZsStzCiOYwvYvrGYcy5u+98BJM18jtdNemwv\nCyDpNGBf2/eUv0PfXmk3EQs1gJsJA3/Ib0n/jO2nYXZJ8JSuImiMDkOwJuqoodap6Y23uO0rJI01\neF4iITYAtteQtBLwFuDrkhab6A3jSZkUGtEyqpHF9uPA1yqFH0Ufp2oM0YCXTi3FTO0yJvpXp4zH\nKpIOndd/2N4v+2QqcI+kGcRibT3gSUlvhn7LqWw/KelnhL/NkoT0fELr4ueHpH8mlAQLESqKW0ns\njFSJURzHurLYtwLfBShG8r0vXoaIlW3fA2D73qLS6w2XVvSSthpIOCPpPX3GnQfnS/ohMZa9mimu\nDGuMFpXXRB011Do1vfEOJEymjyWS3J1nGcDm47xmQikl0W8D3gQ8Rg/XwKRMCjUaWbQEZD5DMuDV\noJZipmoZU8XP2GOEr8woszOwKiGDvp9Qp/VWTiVpL2JS8xfEQv1bwD6d0XcS2wAvJVQTnyMmtlOa\nER3HvivpKmAFYBtJqwBfBs6ue1qp/KekU4nkyBvo2UtJ0tsJv4v3l7gQpWTvIXF8sX2IpG8Rfmmn\n2L4hK3ajMZWprNap6Y33WklL296sxJwG7E9Ch94BZgBfB7ax/VAfAVpSqNFoNIaDWoqZUeU+2yfX\nPolsJC0BnAksDfyYKCH6LbCD7Yd7Dn8Asat3GPD95GRQx2+KWmnJ0tlwoQrn0OgZ25+SdAHwUFHJ\nrAJ8xfY3ap9bIrsC7wZWA8603bdi5mZgGcL3ojOtn0k0T0hD0grAm4FF4lu90/Y/Z55DozFFqanW\nqemNdxBwiaQtgAWJLsFPkqhyJspxZwA7SLoVONj2hHp/tqRQo9FoDAEjuptfk5HoQDQPDgfOsT17\nAifpg4Qxb9+7Xi8CNibUQocWQ9xLgItt391z7I5fSdoZeFTSYYRqqTEFsf3zgeNfkmsKOgwsTixa\nlgNulbRqn90sS/ev4yWdAqxCmPf/ojRQyOQcQol4T3LcRmOqU1OtU80bz/a5pfz4O8BfAl+0fVTf\nccdwPNGk43RgE6I5yDYTGaAlhRqNRqMxctjeu/Y5VGJd23sMPmD7eEm79B24KIMuL/+Q9FaiC9lR\nwAJ9xy/sRpSPnUO00O21NLPRqMgJRNJ1E6KD5/HluG8+ROxqXwPMkHSa7b5Nrgd5xPaMxHiNxqhQ\nU61T1RvP9pmSFiDub1/NiDmGpWx/qRxfL2nbiQ7QkkKNRqPRaIwO45VsPd13YEnrE0qhjYGXE/5Z\nJ5NbXrI4UVazHOFp9FRi7EYjk6VsnyDpfbavLp3+Mng/8IbS+WtB4Gr673w2yM2Stgeuo5jB2r41\nMX6jMVWpqdappqaXdCZzDKZXAa6UdFs5r6yNpUUlLWP7PkkvoYeNtJYUajQajUZjdHhQ0vq2r+0e\nKMmaCa1NH4fDCRPrQ4DrbNdoFV1LPdFopCPp5eXrS0lI/BamdX5hJTGUnXh9JbAusYCD8BZ6ffI5\nNBpTkVHsZAnD8bseAFwt6SHg+YQ344TSkkKNRqPRaIwOewMXSLqC8Fh5GbAlsHXfgW1v2XeMP4Fa\n6olGI5uPAicSSZJzgd2T4v5I0lnAD4GNiDKy3pF0tu332t5M0t62P1Me/15G/EZjqjOq3pfD8HsX\nL6eVJS0NPEDcV4+byBhtMtRoNBqNxohg+05gA8KwcCGiXfVrbd9R87wyqaSeaDRSkLSupAuBjwP/\nBDxOdCBbu+e4ZwPY3pPocLgkcJbtT/QZd4AXDxy/beC4hiKx0Wg0Jhzbvysq62nP+eT/IU0p1Gg0\nGo3GCGH7CeC82ueRiaRX2L4J+BihnliDUE98pOqJNRoTz/zaRp/aY9wXdQe2zwfO7zHWczHh8kzB\nqQAAAZJJREFUC6ZGo9EYIiY82d2SQo1Go9FoNKY650g6xvYXaP4ijalNrbbRq0g6dF7/YXu/nmPD\n3Iukpg5qNBqTngGT60GmAStPdKyWFGo0Go1GozHVWR84QtKlwI6276t9Qo1GT9RqG/0Y4J5jzI9q\nnZEajUajJ8Yztp5ww+tps2a1ZHqj0Wg0Go2pj6RNiA5ks81vE1vKNhq9I+l+4DIiIbL5wPFmtpfp\nMe73bG/W18//E+KP20VwGIxiG41GY5hpSqFGo9FoNBpTnmIwfShwBXBK3bNpNHqjVtvon/X88+dL\nS/w0Go3Gn09TCjUajUaj0ZjSSNoH2A3Yw/ZFtc+n0Wg0Go1GY1hoSqFGo9FoNBpTnfWA9W0/UPtE\nGo1Go9FoNIaJphRqNBqNRqPRaDQajUaj0RhB+u5E0Gg0Go1Go9FoNBqNRqPRGEJaUqjRaDQajUaj\n0Wg0Go1GYwRpSaFGo9FoNBqNRqPRaDQajRGkJYUajUaj0Wg0Go1Go9FoNEaQlhRqNBqNRqPRaDQa\njUaj0RhB/j97d9jjTfVumQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4fa538ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the second step consist of deriving the importance of \n",
    "# each feature and ranking them from the most to the least\n",
    "# important\n",
    "\n",
    "# get feature name and importance\n",
    "features = pd.Series(model_all_features.feature_importances_)\n",
    "features.index = X_train.columns\n",
    "\n",
    "# sort the features by importance\n",
    "features.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# plot\n",
    "features.plot.bar(figsize=(20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage',\n",
       " 'LotArea',\n",
       " 'BsmtUnfSF',\n",
       " 'GrLivArea',\n",
       " 'GarageArea',\n",
       " 'BsmtFinSF1',\n",
       " '1stFlrSF',\n",
       " 'YearBuilt',\n",
       " 'GarageYrBlt',\n",
       " 'MoSold',\n",
       " 'MSSubClass',\n",
       " 'OverallCond',\n",
       " 'MasVnrArea',\n",
       " 'TotalBsmtSF',\n",
       " 'OverallQual',\n",
       " 'OpenPorchSF',\n",
       " 'WoodDeckSF',\n",
       " 'YearRemodAdd',\n",
       " '2ndFlrSF',\n",
       " 'BsmtFinSF2',\n",
       " 'YrSold',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'BedroomAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'Fireplaces',\n",
       " 'HalfBath',\n",
       " 'FullBath',\n",
       " 'MiscVal',\n",
       " 'GarageCars',\n",
       " 'BsmtHalfBath',\n",
       " 'BsmtFullBath',\n",
       " 'KitchenAbvGr',\n",
       " 'LowQualFinSF']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the list of ordered features\n",
    "features = list(features.index)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test one feature xgb R2=0.014262\n"
     ]
    }
   ],
   "source": [
    "# next, we need to build a machine learning\n",
    "# algorithm using only the most important feature\n",
    "\n",
    "# set the seed for reproducibility\n",
    "seed_val = 1000000000\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# build initial model using all the features\n",
    "model_one_feature = xgb.XGBRegressor(\n",
    "    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "# train using only the most important feature\n",
    "model_one_feature.fit(X_train[features[0]].to_frame(), y_train)\n",
    "\n",
    "# calculate the roc-auc in the test set\n",
    "y_pred_test = model_one_feature.predict(X_test[features[0]].to_frame())\n",
    "r2_score_first = r2_score(y_test, y_pred_test)\n",
    "print('Test one feature xgb R2=%f' % (r2_score_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing recursive feature addition\n",
      "\n",
      "testing feature:  LotArea  which is feature  1  out of  36\n",
      "New Test ROC AUC=0.2897947569046587\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.2755329634812618\n",
      "keep:  LotArea\n",
      "\n",
      "testing feature:  BsmtUnfSF  which is feature  2  out of  36\n",
      "New Test ROC AUC=0.21834853148172295\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.204086738058326\n",
      "keep:  BsmtUnfSF\n",
      "\n",
      "testing feature:  GrLivArea  which is feature  3  out of  36\n",
      "New Test ROC AUC=0.5558584058047259\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.541596612381329\n",
      "keep:  GrLivArea\n",
      "\n",
      "testing feature:  GarageArea  which is feature  4  out of  36\n",
      "New Test ROC AUC=0.6567181184109653\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.6424563249875683\n",
      "keep:  GarageArea\n",
      "\n",
      "testing feature:  BsmtFinSF1  which is feature  5  out of  36\n",
      "New Test ROC AUC=0.7553919521136998\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7411301586903029\n",
      "keep:  BsmtFinSF1\n",
      "\n",
      "testing feature:  1stFlrSF  which is feature  6  out of  36\n",
      "New Test ROC AUC=0.7431373073360753\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7288755139126784\n",
      "keep:  1stFlrSF\n",
      "\n",
      "testing feature:  YearBuilt  which is feature  7  out of  36\n",
      "New Test ROC AUC=0.8082134587244378\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7939516653010409\n",
      "keep:  YearBuilt\n",
      "\n",
      "testing feature:  GarageYrBlt  which is feature  8  out of  36\n",
      "New Test ROC AUC=0.8215797498273201\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8073179564039231\n",
      "keep:  GarageYrBlt\n",
      "\n",
      "testing feature:  MoSold  which is feature  9  out of  36\n",
      "New Test ROC AUC=0.7989006749306045\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7846388815072075\n",
      "keep:  MoSold\n",
      "\n",
      "testing feature:  MSSubClass  which is feature  10  out of  36\n",
      "New Test ROC AUC=0.8093193201219485\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7950575266985516\n",
      "keep:  MSSubClass\n",
      "\n",
      "testing feature:  OverallCond  which is feature  11  out of  36\n",
      "New Test ROC AUC=0.81952779582292\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8052660023995231\n",
      "keep:  OverallCond\n",
      "\n",
      "testing feature:  MasVnrArea  which is feature  12  out of  36\n",
      "New Test ROC AUC=0.7892839102393363\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7750221168159394\n",
      "keep:  MasVnrArea\n",
      "\n",
      "testing feature:  TotalBsmtSF  which is feature  13  out of  36\n",
      "New Test ROC AUC=0.8042093785540418\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7899475851306449\n",
      "keep:  TotalBsmtSF\n",
      "\n",
      "testing feature:  OverallQual  which is feature  14  out of  36\n",
      "New Test ROC AUC=0.8113817682628988\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7971199748395018\n",
      "keep:  OverallQual\n",
      "\n",
      "testing feature:  OpenPorchSF  which is feature  15  out of  36\n",
      "New Test ROC AUC=0.8059577840185053\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7916959905951083\n",
      "keep:  OpenPorchSF\n",
      "\n",
      "testing feature:  WoodDeckSF  which is feature  16  out of  36\n",
      "New Test ROC AUC=0.8026151996609769\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.78835340623758\n",
      "keep:  WoodDeckSF\n",
      "\n",
      "testing feature:  YearRemodAdd  which is feature  17  out of  36\n",
      "New Test ROC AUC=0.8124924853871003\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7982306919637033\n",
      "keep:  YearRemodAdd\n",
      "\n",
      "testing feature:  2ndFlrSF  which is feature  18  out of  36\n",
      "New Test ROC AUC=0.814925792055301\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8006639986319041\n",
      "keep:  2ndFlrSF\n",
      "\n",
      "testing feature:  BsmtFinSF2  which is feature  19  out of  36\n",
      "New Test ROC AUC=0.8189283122089718\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8046665187855748\n",
      "keep:  BsmtFinSF2\n",
      "\n",
      "testing feature:  YrSold  which is feature  20  out of  36\n",
      "New Test ROC AUC=0.8091731669449771\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7949113735215801\n",
      "keep:  YrSold\n",
      "\n",
      "testing feature:  ScreenPorch  which is feature  21  out of  36\n",
      "New Test ROC AUC=0.8102718511465637\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7960100577231668\n",
      "keep:  ScreenPorch\n",
      "\n",
      "testing feature:  PoolArea  which is feature  22  out of  36\n",
      "New Test ROC AUC=0.8193707033325414\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8051089099091444\n",
      "keep:  PoolArea\n",
      "\n",
      "testing feature:  BedroomAbvGr  which is feature  23  out of  36\n",
      "New Test ROC AUC=0.8159055270231841\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8016437335997871\n",
      "keep:  BedroomAbvGr\n",
      "\n",
      "testing feature:  TotRmsAbvGrd  which is feature  24  out of  36\n",
      "New Test ROC AUC=0.8137964005888094\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7995346071654125\n",
      "keep:  TotRmsAbvGrd\n",
      "\n",
      "testing feature:  EnclosedPorch  which is feature  25  out of  36\n",
      "New Test ROC AUC=0.8083144979317314\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7940527045083344\n",
      "keep:  EnclosedPorch\n",
      "\n",
      "testing feature:  3SsnPorch  which is feature  26  out of  36\n",
      "New Test ROC AUC=0.8071898088189728\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.7929280153955759\n",
      "keep:  3SsnPorch\n",
      "\n",
      "testing feature:  Fireplaces  which is feature  27  out of  36\n",
      "New Test ROC AUC=0.8180332423243601\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8037714489009632\n",
      "keep:  Fireplaces\n",
      "\n",
      "testing feature:  HalfBath  which is feature  28  out of  36\n",
      "New Test ROC AUC=0.8167862654258069\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.80252447200241\n",
      "keep:  HalfBath\n",
      "\n",
      "testing feature:  FullBath  which is feature  29  out of  36\n",
      "New Test ROC AUC=0.8309852784386307\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8167234850152337\n",
      "keep:  FullBath\n",
      "\n",
      "testing feature:  MiscVal  which is feature  30  out of  36\n",
      "New Test ROC AUC=0.8295292768849214\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8152674834615244\n",
      "keep:  MiscVal\n",
      "\n",
      "testing feature:  GarageCars  which is feature  31  out of  36\n",
      "New Test ROC AUC=0.827733715229565\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.813471921806168\n",
      "keep:  GarageCars\n",
      "\n",
      "testing feature:  BsmtHalfBath  which is feature  32  out of  36\n",
      "New Test ROC AUC=0.8254282843747686\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8111664909513716\n",
      "keep:  BsmtHalfBath\n",
      "\n",
      "testing feature:  BsmtFullBath  which is feature  33  out of  36\n",
      "New Test ROC AUC=0.826592472214823\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8123306787914261\n",
      "keep:  BsmtFullBath\n",
      "\n",
      "testing feature:  KitchenAbvGr  which is feature  34  out of  36\n",
      "New Test ROC AUC=0.8210760637169443\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8068142702935474\n",
      "keep:  KitchenAbvGr\n",
      "\n",
      "testing feature:  LowQualFinSF  which is feature  35  out of  36\n",
      "New Test ROC AUC=0.8224042647862362\n",
      "All features Test ROC AUC=0.014261793423396951\n",
      "Increase in r2 = 0.8081424713628392\n",
      "keep:  LowQualFinSF\n",
      "DONE!!\n",
      "total features to keep:  36\n"
     ]
    }
   ],
   "source": [
    "# the final step consists in adding one at a time\n",
    "# all the features, from the most to the least\n",
    "# important, and build an xgboost at each round.\n",
    "\n",
    "# once we build the model, we calculate the new r2\n",
    "# if the new r2 is bigger than the original one\n",
    "# (with one feature), then that feature that was added\n",
    "# was important, and we should keep it.\n",
    "# otherwise, we should remove the feature\n",
    "\n",
    "# recursive feature addition:\n",
    "\n",
    "# first we arbitrarily set the increase in r2\n",
    "# if the increase is above this threshold,\n",
    "# the feature will be kept\n",
    "tol = 0.001\n",
    "\n",
    "print('doing recursive feature addition')\n",
    "\n",
    "# we initialise a list where we will collect the\n",
    "# features we should keep\n",
    "features_to_keep = [features[0]]\n",
    "\n",
    "# set a counter to know how far ahead the loop is going\n",
    "count = 1\n",
    "\n",
    "# now we loop over all the features, in order of importance:\n",
    "# remember that features is the list of ordered features\n",
    "# by importance\n",
    "for feature in features[1:]:\n",
    "    print()\n",
    "    print('testing feature: ', feature, ' which is feature ', count,\n",
    "          ' out of ', len(features))\n",
    "    count = count + 1\n",
    "\n",
    "    # initialise model\n",
    "    model_int = xgb.XGBRegressor(\n",
    "        nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "    # fit model with the selected features\n",
    "    # and the feature to be evaluated\n",
    "    model_int.fit(\n",
    "        X_train[features_to_keep + [feature] ], y_train)\n",
    "\n",
    "    # make a prediction over the test set\n",
    "    y_pred_test = model_int.predict(\n",
    "        X_test[features_to_keep + [feature] ])\n",
    "\n",
    "    # calculate the new r2\n",
    "    r2_score_int = r2_score(y_test, y_pred_test)\n",
    "    print('New Test ROC AUC={}'.format((r2_score_int)))\n",
    "\n",
    "    # print the original roc-auc with all the features\n",
    "    print('All features Test ROC AUC={}'.format((r2_score_first)))\n",
    "\n",
    "    # determine the drop in the roc-auc\n",
    "    diff_r2 = r2_score_int - r2_score_first\n",
    "\n",
    "    # compare the increase in r2 with the tolerance\n",
    "    # we set previously\n",
    "    if diff_r2 >= tol:\n",
    "        print('Increase in r2 = {}'.format(diff_r2))\n",
    "        print('keep: ', feature)\n",
    "        print\n",
    "        # if the increase in the r2 is bigger than the threshold\n",
    "        # we keep the feature and re-adjust the r2 to the new value\n",
    "        # considering the added feature\n",
    "        auc_score_first = auc_score_int\n",
    "        \n",
    "        # and we append the feature to keep to the list\n",
    "        features_to_keep.append(feature)\n",
    "    else:\n",
    "        # we ignore the feature\n",
    "        print('Increase in r2 = {}'.format(diff_r2))\n",
    "        print('remove: ', feature)\n",
    "        print\n",
    "\n",
    "\n",
    "# now the loop is finished, we evaluated all the features\n",
    "print('DONE!!')\n",
    "print('total features to keep: ', len(features_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test selected features ROC AUC=0.822404\n"
     ]
    }
   ],
   "source": [
    "# capture the 36 selected features\n",
    "seed_val = 1000000000\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# build initial model\n",
    "final_xgb = xgb.XGBRegressor(\n",
    "    nthread=10, max_depth=4, n_estimators=500, learning_rate=0.05)\n",
    "\n",
    "# fit the model with the selected features\n",
    "final_xgb.fit(X_train[features_to_keep], y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred_test = final_xgb.predict(X_test[features_to_keep])\n",
    "\n",
    "# calculate roc-auc\n",
    "r2_score_final = r2_score(y_test, y_pred_test)\n",
    "print('Test selected features ROC AUC=%f' % (r2_score_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the model built with 36 features (r2: 0.822) performs better than the model built with one feature (r2: 0.014) and the model built with all the features (r2: 0.818).\n",
    "\n",
    "However, from the previous lecture we know that a model built with 23 features shows a performance of 0.88. Then, if we increase the threshold here, we should be able to reduce the number of features a bit further and potentially increase the performance of our model.\n",
    "\n",
    "Why don't you go ahead and try different thresholds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
